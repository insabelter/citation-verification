<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Machine learning of accurate energy-conserving molecular force fields</title>
				<funder>
					<orgName type="full">European Research Council</orgName>
				</funder>
				<funder ref="#_HM2svKr">
					<orgName type="full">Deutsche Forschungsgemeinschaft</orgName>
				</funder>
				<funder>
					<orgName type="full">ERC-CoG</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Stefan</forename><surname>Chmiela</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
								<address>
									<postCode>10587</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandre</forename><surname>Tkatchenko</surname></persName>
							<email>alexandre.tkatchenko@uni.lu</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Physics and Materials Science Research Unit</orgName>
								<orgName type="institution">University of Luxembourg</orgName>
								<address>
									<postCode>L-1511</postCode>
									<settlement>Luxembourg</settlement>
									<country key="LU">Luxembourg</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Fritz-Haber-Institut</orgName>
								<orgName type="institution">Max-Planck-Gesellschaft</orgName>
								<address>
									<postCode>14195</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huziel</forename><forename type="middle">E</forename><surname>Sauceda</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Fritz-Haber-Institut</orgName>
								<orgName type="institution">Max-Planck-Gesellschaft</orgName>
								<address>
									<postCode>14195</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Igor</forename><surname>Poltavsky</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Physics and Materials Science Research Unit</orgName>
								<orgName type="institution">University of Luxembourg</orgName>
								<address>
									<postCode>L-1511</postCode>
									<settlement>Luxembourg</settlement>
									<country key="LU">Luxembourg</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kristof</forename><forename type="middle">T</forename><surname>Schütt</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
								<address>
									<postCode>10587</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
							<email>klaus-robert.mueller@tu-berlin.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
								<address>
									<postCode>10587</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Brain and Cognitive Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
								<address>
									<addrLine>Seongbuk-gu</addrLine>
									<postCode>136-713</postCode>
									<settlement>Anam-dong Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
								<address>
									<addrLine>Stuhlsatzenhausweg</addrLine>
									<postCode>66123</postCode>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Machine learning of accurate energy-conserving molecular force fields</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2AA7A5093D2A33F34512EA8909336258</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-03-11T09:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Using conservation of energy-a fundamental property of closed classical and quantum mechanical systemswe develop an efficient gradient-domain machine learning (GDML) approach to construct accurate molecular force fields using a restricted number of samples from ab initio molecular dynamics (AIMD) trajectories. The GDML implementation is able to reproduce global potential energy surfaces of intermediate-sized molecules with an accuracy of 0.3 kcal mol -1 for energies and 1 kcal mol -1 Å -1 for atomic forces using only 1000 conformational geometries for training. We demonstrate this accuracy for AIMD trajectories of molecules, including benzene, toluene, naphthalene, ethanol, uracil, and aspirin. The challenge of constructing conservative force fields is accomplished in our work by learning in a Hilbert space of vector-valued functions that obey the law of energy conservation. The GDML approach enables quantitative molecular dynamics simulations for molecules at a fraction of cost of explicit AIMD calculations, thereby allowing the construction of efficient force fields with the accuracy and transferability of high-level ab initio methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Within the Born-Oppenheimer (BO) approximation, predictive simulations of properties and functions of molecular systems require an accurate description of the global potential energy hypersurface V BO ( r</p><formula xml:id="formula_0">→ 1 , r → 2 , …, r → N ),</formula><p>where r → i indicates the nuclear Cartesian coordinates. Although V BO could, in principle, be obtained on the fly using explicit ab initio calculations, more efficient approaches that can access the long time scales are required to understand relevant phenomena in large molecular systems. A plethora of classical mechanistic approximations to V BO have been constructed, in which the parameters are typically fitted to a small set of ab initio calculations or experimental data. Unfortunately, these classical approximations may suffer from the lack of transferability and can yield accurate results only close to the conditions (geometries) they have been fitted to. Alternatively, sophisticated machine learning (ML) approaches that can accurately reproduce the global potential energy surface (PES) for elemental materials <ref type="bibr" target="#b0">(1)</ref><ref type="bibr" target="#b1">(2)</ref><ref type="bibr" target="#b2">(3)</ref><ref type="bibr" target="#b3">(4)</ref><ref type="bibr" target="#b4">(5)</ref><ref type="bibr" target="#b5">(6)</ref><ref type="bibr" target="#b6">(7)</ref><ref type="bibr" target="#b7">(8)</ref><ref type="bibr" target="#b8">(9)</ref> and small molecules <ref type="bibr" target="#b9">(10)</ref><ref type="bibr" target="#b10">(11)</ref><ref type="bibr" target="#b11">(12)</ref><ref type="bibr" target="#b12">(13)</ref><ref type="bibr" target="#b13">(14)</ref><ref type="bibr" target="#b14">(15)</ref><ref type="bibr" target="#b15">(16)</ref> have been recently developed (see Fig. <ref type="figure" target="#fig_0">1, A</ref> and<ref type="figure">B</ref>) <ref type="bibr" target="#b16">(17)</ref>. Although potentially very promising, one particular challenge for direct ML fitting of molecular PES is the large amount of data necessary to obtain an accurate model. Often, many thousands or even millions of atomic configurations are used as training data for ML models. This results in nontransparent models, which are difficult to analyze and may break consistency <ref type="bibr" target="#b17">(18)</ref> between energies and forces.</p><p>A fundamental property that any force field</p><formula xml:id="formula_1">F i ( r → 1 , r → 2 , …, r → N</formula><p>) must satisfy is the conservation of total energy, which implies that</p><formula xml:id="formula_2">F i ð → r 1 ; → r 2 ; …; → r N Þ ¼ À∇ → ri Vð → r 1 ; → r 2 ; …; → r N Þ.</formula><p>Any classical mechanistic expressions for the potential energy (also denoted as classical force field) or analytically derivable ML approaches trained on energies satisfy energy conservation by construction. However, even if conserva-tion of energy is satisfied implicitly within an approximation, this does not imply that the model will be able to accurately follow the trajectory of the true ab initio potential, which was used to fit the force field. In particular, small energy/force inconsistencies between the force field model and ab initio calculations can lead to unforeseen artifacts in the PES topology, such as spurious critical points that can give rise to incorrect molecular dynamics (MD) trajectories. Another fundamental problem is that classical and ML force fields focusing on energy as the main observable have to assume atomic energy additivity-an approximation that is hard to justify from quantum mechanics.</p><p>Here, we present a robust solution to these challenges by constructing an explicitly conservative ML force field, which uses exclusively atomic gradient information in lieu of atomic (or total) energies. In this manner, with any number of data samples, the proposed model fulfills energy conservation by construction. Obviously, the developed ML force field can be coupled to a heat bath, making the full system (molecule and bath) non-energy-conserving.</p><p>We remark that atomic forces are true quantum-mechanical observables within the BO approximation by virtue of the Hellmann-Feynman theorem. The energy of a molecular system is recovered by analytic integration of the force-field kernel (see Fig. <ref type="figure" target="#fig_0">1C</ref>). We demonstrate that our gradient-domain machine learning (GDML) approach is able to accurately reproduce global PESs of intermediate-sized molecules within 0.3 kcal mol -1 for energies and 1 kcal mol -1 Å -1 for atomic forces relative to the reference data. This accuracy is achieved when using less than 1000 training geometries to construct the GDML model and using energy conservation to avoid overfitting and artifacts. Hence, the GDML approach paves the way for efficient and precise MD simulations with PESs that are obtained with arbitrary high-level quantumchemical approaches. We demonstrate the accuracy of GDML by computing AIMD-quality thermodynamic observables using pathintegral MD (PIMD) for eight organic molecules with up to 21 atoms and four chemical elements. Although we use density functional theory (DFT) calculations as reference in this development work, it is possible to use any higher-level quantum-chemical reference data. With state-of-the-art quantum chemistry codes running on current highperformance computers, it is possible to generate accurate reference data for molecules with a few dozen atoms. Here, we focus on intramolecular forces in small-and medium-sized molecules. However, in the future, the GDML model should be combined with an accurate model for intermolecular forces to enable predictive simulations of condensed molecular systems. Widely used classical mechanistic force fields are based on simple harmonic terms for intramolecular degrees of freedom. Our GDML model correctly treats anharmonicities by using no assumptions whatsoever on the analytic form on the interatomic potential energy functions within molecules. Modeling the true vector field (leftmost subfigure) based on a small number of vector samples With GDML, a conservative vector field estimate f F is obtained directly. A naïve estimator f À F with independent predictions for each element of the output vector is not capable of imposing energy conservation constraints. We perform a Helmholtz decomposition of this nonconservative vector field to show the error component that violates the law of energy conservation. This is the portion of the overall prediction error that was avoided with GDML because of the addition of the energy conservation constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHODS</head><p>The GDML approach explicitly constructs an energy-conserving force field, avoiding the application of the noise-amplifying derivative operator to a parameterized potential energy model (see the Supplementary Materials for details). This can be achieved by directly learning the functional relationship</p><formula xml:id="formula_3">f F :ð → r 1 ; → r 2 ; …; → r N Þ i → ML F i<label>ð1Þ</label></formula><p>between atomic coordinates and interatomic forces, instead of computing the gradient of the PES (see Fig. <ref type="figure" target="#fig_0">1, C</ref> and<ref type="figure">B</ref>). This requires constraining the solution space of all arbitrary vector fields to the subset of energy-conserving gradient fields. The PES can be obtained through direct integration of f F up to an additive constant.</p><p>To construct f F , we used a generalization of the commonly used kernel ridge regression technique for structured vector fields (see the Supplementary Materials for details) <ref type="bibr" target="#b18">(19)</ref><ref type="bibr" target="#b19">(20)</ref><ref type="bibr" target="#b20">(21)</ref>. GDML solves the normal equation of the ridge estimator in the gradient domain using the Hessian matrix of a kernel as the covariance structure. It maps to all partial forces of a molecule simultaneously (see Fig. <ref type="figure" target="#fig_0">1A</ref>)</p><formula xml:id="formula_4">K Hess κ ð Þ þ λI À Á → a ¼ ∇V BO ¼ -F<label>ð2Þ</label></formula><p>We resorted to the extensive body of research on suitable kernels and descriptors for the energy prediction task <ref type="bibr" target="#b9">(10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17)</ref>.</p><p>For our application, we considered a subclass from the parametric Matérn family <ref type="bibr" target="#b21">(22)</ref><ref type="bibr" target="#b22">(23)</ref><ref type="bibr" target="#b23">(24)</ref> of (isotropic) kernel functions To disambiguate Cartesian geometries that are physically equivalent, we use an input descriptor derived from the Coulomb matrix (see the Supplementary Materials for details) <ref type="bibr" target="#b9">(10)</ref>.</p><formula xml:id="formula_5">κ : C v¼nþ 1 2 d ð Þ ¼ exp - ffiffiffiffiffi 2v p d σ P n d ð Þ; P n d ð Þ ¼ ∑ n k¼0 ðn þ kÞ!<label>ð2nÞ</label></formula><formula xml:id="formula_6">! n k 2 ffiffiffiffiffi 2v p d σ n-k<label>ð3Þ</label></formula><formula xml:id="formula_7">where d ¼ ∥x → À x → ′∥</formula><p>The trained force field estimator collects the contributions of the partial derivatives 3N of all training points M to compile the prediction. It takes the form</p><formula xml:id="formula_8">f F → x À Á ¼ ∑ M i¼1 ∑ 3N j¼1 → a i À Á j ∂ ∂x j ∇κ → x ; → x i À Á<label>ð4Þ</label></formula><p>and a corresponding energy predictor is obtained by integrating f F ðx → Þ with respect to the Cartesian geometry. Because the trained model is a (fixed) linear combination of kernel functions, integration only affects the kernel function itself. The expression</p><formula xml:id="formula_9">f E → x À Á ¼ ∑ M i¼1 ∑ 3N j¼1 → a i À Á j ∂ ∂x j κ → x ; → x i À Á<label>ð5Þ</label></formula><p>for the energy predictor is therefore neither problem-specific nor does it require retraining. We remark that our PES model is global in the sense that each molecular descriptor is considered as a whole entity, bypassing the need for arbitrary partitioning of energy into atomic contributions. This allows the GDML framework to capture chemical and longrange interactions. Obviously, long-range electrostatic and van der Waals interactions that fall within the error of the GDML model will have to be incorporated with explicit physical models. Other approaches that use ML to fit PESs such as Gaussian approximation potentials (3, 8) have been proposed. However, these approaches consider an explicit localization of the contribution of individual atoms to the total energy. The total energy is expressed as a linear combination of local environments characterized by a descriptor that acts as a nonunique partitioning function to the total energy. Training on force samples similarly requires the evaluation of kernel derivatives, but w. r.t. those local environments. Although any partitioning of the total energy is arbitrary, our molecular total energy is physically meaningful in that it is related to the atomic force, thus being a measure for the deflection of every atom from its ground state.</p><p>We first demonstrate the impact of the energy conservation constraint on a toy model that can be easily visualized. A nonconservative force model f À F was trained alongside our GDML model f F on a synthetic potential defined by a two-dimensional harmonic oscillator using the same samples, descriptor, and kernel.</p><p>We were interested in a qualitative assessment of the prediction error that is introduced as a direct result of violating the law of energy conservation.</p><p>For this, we uniquely decomposed our naïve estimate</p><formula xml:id="formula_10">f À F ¼ À∇E þ ∇ Â A<label>ð6Þ</label></formula><p>into a sum of a curl-free (conservative) and a divergence-free (solenoidal) vector field, according to the Helmholtz theorem (see Fig. <ref type="figure">2</ref>) <ref type="bibr" target="#b24">(25)</ref>. This was achieved by subsampling f À F on a regular grid and numerically projecting it onto the closest conservative vector field by solving Poisson's equation ( <ref type="formula">26</ref>)</p><formula xml:id="formula_11">À∇ 2 E ! ¼ ∇ f À F<label>ð7Þ</label></formula><p>with Neumann boundary conditions. The remaining solenoidal field represents the systematic error made by the naïve estimator. Other than in this example, our GDML approach directly estimates the conservative vector field and does not require a costly numerical projection on a dense grid of regularly spaced samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head><p>We now proceed to evaluate the performance of the GDML approach by learning and then predicting AIMD trajectories for molecules, including benzene, uracil, naphthalene, aspirin, salicylic acid, malonaldehyde, ethanol, and toluene (see table <ref type="table">S1</ref> for details of these molecular data sets). These data sets range in size from 150 k to nearly 1 M conformational geometries with a resolution of 0.5 fs, although only a drastically reduced subset is necessary to train our energy and GDML predictors. The molecules have different sizes, and the molecular PESs exhibit different levels of complexity. The energy range across all data points within a set spans from 20 to 48 kcal mol -1 . Force components range from 266 to 570 kcal mol -1 Å -1 . The total energy and force labels for each data set were computed using the PBE + vdW-TS electronic structure method <ref type="bibr" target="#b26">(27,</ref><ref type="bibr" target="#b27">28)</ref>.</p><p>The GDML prediction results are contrasted with the output of a model that has been trained on energies. Both models use the same kernel and descriptor, but the hyperparameter search was performed individually to ensure optimal model selection. The GDML model for each data set was trained on ~1000 geometries, sampled uniformly according to the MD@DFT trajectory energy distribution. For the energy model, we multiplied this amount by the number of atoms in one molecule times its three spatial degrees of freedom. This configuration yields equal kernel sizes for both models and therefore equal levels of complexity in terms of the optimization problem. We compare the models on the basis of the required number of samples (Fig. <ref type="figure" target="#fig_1">3A</ref>) to achieve a force prediction accuracy of 1 kcal mol -1 Å -1 . Furthermore, the prediction accuracy of the force and energy estimates for fully converged models (w.r.t. number of samples) (Fig. <ref type="figure" target="#fig_1">3, B</ref> and<ref type="figure">C</ref>) are judged on the basis of the mean absolute error (MAE) and root mean square error performance measures.</p><p>It can be seen in Fig. <ref type="figure" target="#fig_1">3A</ref> that the GDML model achieves a force accuracy of 1 kcal mol -1 Å -1 using only ~1000 samples from different data sets. Conversely, a pure energy-based model would require up to two orders of magnitude more samples to achieve a similar accuracy. The superior performance of the GDML model cannot be simply attributed to the greater information content of force samples. We compare our results to those of a naïve force model along the lines of the toy example shown in Fig. <ref type="figure">2</ref> (see tables S1 and S3 for details on the prediction accuracy of both models). The naïve force model is nonconservative but identical to the GDML model in all other aspects. Note that its performance deteriorates significantly on all data sets compared to the full GDML model (see the Supplementary Materials for details). We note here that we used DFT calculations, but any other high-level quantum chemistry approach could have been used to calculate forces for 1000 conformational geometries. This allows AIMD simulations to be carried out at the speed of ML models with the accuracy of correlated quantum chemistry calculations.</p><p>It is noticeable that the GDML model at convergence (w.r.t. number of samples) yields higher accuracy for forces than an equivalent energybased model (see Fig. <ref type="figure" target="#fig_1">3B</ref>). Here, we should remark that the energybased model trained on a very large data set can reduce the energy error to below 0.1 kcal mol -1 , whereas the GDML energy error remains at 0.2 kcal mol -1 for ~1000 training samples (see Fig. <ref type="figure" target="#fig_1">3C</ref>). However, these errors are already significantly below thermal fluctuations (k B T) at room temperature (~0.6 kcal mol -1 ), indicating that the GDML model provides an excellent description of both energies and forces, fully preserves their consistency, and reduces the complexity of the ML model. These are all desirable features of models that combine rigorous physical laws with the power of data-driven machines.</p><p>The ultimate test of any force field model is to establish its aptitude to predict statistical averages and fluctuations using MD simulations. The quantitative performance of the GDML model is demonstrated in Fig. <ref type="figure" target="#fig_2">4</ref> for classical and quantum MD simulations of aspirin at T = 300 K. Figure <ref type="figure" target="#fig_2">4A</ref> shows a comparison of interatomic distance distributions, h(r), from MD@DFT and MD@GDML. Overall, we observe a quantitative agreement in h(r) between DFT and GDML simulations. The small differences in the distance range between 4.3 and 4.7 Å result from slightly higher energy barriers of the GDML model in the pathway from A to B corresponding to the collective motions of the carboxylic acid and ester groups in aspirin. These differences vanish once the quantum nature of the nuclei is introduced in the PIMD simulations <ref type="bibr" target="#b28">(29)</ref>. In addition, long-time scale simulations are required to completely understand the dynamics of molecular systems. Figure <ref type="figure" target="#fig_2">4B</ref> shows the probability distribution of the fluctuations of dihedral angles of carboxylic acid and ester groups in aspirin. This plot shows the existence of two main metastable configurations A and B and a shortlived configuration C, illustrating the nontrivial dynamics captured by the GDML model. Finally, we remark that a similarly good performance as for aspirin is also observed for the other seven molecules shown in Fig. <ref type="figure" target="#fig_1">3</ref>. The efficiency of the GDML model (which is three orders of magnitude faster than DFT) should enable long-time scale PIMD simulations to obtain converged thermodynamic properties of intermediate-sized molecules with the accuracy and transferability of high-level ab initio methods.</p><p>In summary, the developed GDML model allows the construction of complex multidimensional PES by combining rigorous physical laws with data-driven ML techniques. In addition to the presented successful applications to the model systems and intermediate-sized molecules, our work can be further developed in several directions, including scaling with system size and complexity, incorporating additional physical priors, describing reaction pathways, and enabling seamless coupling between GDML and ab initio calculations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The construction of ML models: First, reference data from an MD trajectory are sampled. (A) The geometry of each molecule is encoded in a descriptor. This representation introduces elementary transformational invariances of energy and constitutes the first part of the prior. A kernel function then relates all descriptors to form the kernel matrix-the second part of the prior. The kernel function encodes similarity between data points. Our particular choice makes only weak assumptions: It limits the frequency spectrum of the resulting model and adds the energy conservation constraint. Hess, Hessian. (C) These general priors are sufficient to reproduce good estimates from a restricted number of force samples. (B) A comparable energy model is not able to reproduce the PES to the same level of detail.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Efficiency of GDML predictor versus a model that has been trained on energies. (A) Required number of samples for a force prediction performance of MAE (1 kcal mol -1 Å -1 ) with the energy-based model (gray) and GDML (blue). The energy-based model was not able to achieve the targeted performance with the maximum number of 63,000 samples for aspirin. (B) Force prediction errors for the converged models (same number of partial derivative samples and energy samples). (C) Energy prediction errors for the converged models. All reported prediction errors have been estimated via cross-validation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Results of classical and PIMD simulations. The recently developed estimators based on perturbation theory were used to evaluate structural and electronic observables (30). (A) Comparison of the interatomic distance distributions, h r ð Þ ¼ 〈 2 NðN À 1Þ</figDesc><graphic coords="4,37.42,55.79,252.00,106.92" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Chmiela et al., Sci. Adv. 2017; 3 : e1603015 5 May 2017 1 of 6 Downloaded from https://www.science.org on March 04, 2025</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Chmiela et al., Sci. Adv. 2017; 3 : e1603015 5 May 2017 2 of 6 Downloaded from https://www.science.org on March 04, 2025</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Chmiela et al., Sci. Adv. 2017; 3 : e1603015 5 May 2017 3 of 6 Downloaded from https://www.science.org on March 04, 2025</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>Chmiela et al., Sci. Adv. 2017; 3 : e1603015 5 May 2017 4 of 6 Downloaded from https://www.science.org on March 04, 2025</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>Chmiela et al., Sci. Adv. 2017; 3 : e1603015 5 May 2017 5 of 6 Downloaded from https://www.science.org on March 04, 2025</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>Chmiela et al., Sci. Adv. 2017; 3 : e1603015 5 May 2017 6 of 6 Downloaded from https://www.science.org on March 04, 2025</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments Funding: S.C., A.T., and K.-R.M. thank the <rs type="funder">Deutsche Forschungsgemeinschaft</rs> (project <rs type="projectName">MU</rs> <rs type="grantNumber">987/ 20-1</rs>) for funding this work. A.T. is funded by the <rs type="funder">European Research Council</rs> with <rs type="funder">ERC-CoG</rs></p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_HM2svKr">
					<idno type="grant-number">987/ 20-1</idno>
					<orgName type="project" subtype="full">MU</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTARY MATERIALS</head><p>Supplementary material for this article is available at <ref type="url" target="http://advances.sciencemag.org/cgi/content/full/3/5/e1603015/DC1">http://advances.sciencemag.org/cgi/ content/full/3/5/e1603015/DC1</ref> section S1. Noise amplification by differentiation section S2. Vector-valued kernel learning section S3. Descriptors section S4. Model analysis section S5. Details of the PIMD simulation fig. S1. The accuracy of the GDML model (in terms of the MAE) as a function of training set size: Chemical accuracy of less than 1 kcal/mol is already achieved for small training sets. fig. <ref type="figure">S2</ref>. Predicting energies and forces for consecutive time steps of an MD simulation of uracil at 500 K. table <ref type="table">S1</ref>. Properties of MD data sets that were used for numerical testing. table <ref type="table">S2</ref>. GDML prediction accuracy for interatomic forces and total energies for all data sets. table <ref type="table">S3</ref>. Accuracy of the naïve force predictor. table <ref type="table">S4</ref>. Accuracy of the converged energy-based predictor. References <ref type="bibr" target="#b30">(31)</ref><ref type="bibr" target="#b31">(32)</ref><ref type="bibr" target="#b32">(33)</ref><ref type="bibr" target="#b33">(34)</ref><ref type="bibr" target="#b34">(35)</ref><ref type="bibr" target="#b35">(36)</ref> grant BeStMo. K.-R.M. gratefully acknowledges the BK21 program funded by the Korean National Research Foundation grant (no. 2012-005741). Additional support was provided by the Federal Ministry of Education and Research (BMBF) for the Berlin Big Data Center BBDC (01IS14013A). Part of this research was performed while the authors were visiting the Institute for Pure and Applied Mathematics, which is supported by the NSF. Author contributions: S.C. conceived, constructed, and analyzed the GDML models. S.C., A.T., and K.-R.M. developed the theory and designed the analyses. H.E.S. and I.P. performed the DFT calculations and MD simulations. H.E.S. helped with the analyses. K.T.S. and A.T. helped with the figures. A.T., S.C., and K.-R.M. wrote the paper with contributions from other authors. All authors discussed the results and commented on the manuscript. Competing interests: The authors declare that they have no competing interests. Data and materials availability: All data sets used in this work are available at <ref type="url" target="http://quantum-machine.org/datasets/">http://quantum-machine.org/datasets/</ref>. Additional data related to this paper may be requested from the authors. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Generalized neural-network representation of high-dimensional potential-energy surfaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Behler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Parrinello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page">146401</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Representing molecule-surface interactions with symmetryadapted neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Behler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Reuter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Phys</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page">14705</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Gaussian approximation potentials: The accuracy of quantum mechanics, without the electrons</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Bartók</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Csányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page">136403</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Atom-centered symmetry functions for constructing high-dimensional neural network potentials</title>
		<author>
			<persName><forename type="first">J</forename><surname>Behler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Phys</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page">74106</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural network potential-energy surfaces in chemistry: A tool for large-scale simulations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Behler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Chem. Chem. Phys</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="17930" to="17955" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Construction of high-dimensional neural network potentials using environment-dependent atom pairs</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V J</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Artrith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Behler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Phys</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="page">194111</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On representing chemical environments</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Bartók</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Csányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. B</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page">184115</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Gaussian approximation potentials: A brief tutorial introduction</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Bartók</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Csányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Quantum Chem</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="1051" to="1057" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Comparing molecules and solids across structural and alchemical space</title>
		<author>
			<persName><forename type="first">S</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Bartók</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Csányi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ceriotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Chem. Chem. Phys</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="13754" to="13769" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fast and accurate modeling of molecular atomization energies with machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tkatchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Lilienfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page">58301</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Machine learning of molecular electronic properties in chemical compound space</title>
		<author>
			<persName><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gobre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vazquez-Mayagoitia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tkatchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Lilienfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New J. Phys</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">95003</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Assessment and validation of machine learning methods for predicting molecular atomization energies</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Biegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fazli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scheffler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Von Lilienfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tkatchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Theory Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="3404" to="3419" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Machine learning predictions of molecular properties: Accurate many-body potentials and nonlocality in chemical space</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Biegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pronobis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Von Lilienfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tkatchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Phys. Chem. Lett</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="2326" to="2331" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Machine learning for quantum mechanical properties of atoms in molecules</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Lilienfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Phys. Chem. Lett</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="3309" to="3313" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning scheme to predict atomic forces and accelerate materials simulations</title>
		<author>
			<persName><forename type="first">V</forename><surname>Botu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramprasad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. B</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page">94306</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Quantum energy regression using scattering transforms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hirn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Poilvert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.02077</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Perspective: Machine learning potentials for atomistic simulations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Behler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Phys</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page">170901</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Molecular dynamics with on-the-fly machine learning of quantum-mechanical forces</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Kermode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">De</forename><surname>Vita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page">96405</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On learning vector-valued functions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Micchelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="177" to="204" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Universal multi-task kernels</title>
		<author>
			<persName><forename type="first">A</forename><surname>Caponnetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Micchelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1615" to="1646" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Scalable matrix-valued kernel learning for highdimensional nonlinear multivariate regression and granger causality</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Q</forename><surname>Minh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Lozano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Conference on Uncertainty in Artificial Intelligence (UAI&apos;13)</title>
		<meeting>the 29th Conference on Uncertainty in Artificial Intelligence (UAI&apos;13)</meeting>
		<imprint>
			<date type="published" when="2013-07-14">12 to 14 July 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Spatial Variation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Matérn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lecture Notes in Statistics</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Gradshteyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Ryzhik</surname></persName>
		</author>
		<title level="m">Table of Integrals, Series, and Products</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Jeffrey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Zwillinger</surname></persName>
		</editor>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Matérn cross-covariance functions for multivariate random fields</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gneiting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kleiber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schlather</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="1167" to="1177" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Über Integrale der hydrodynamischen Gleichungen, welche den Wirbelbewegungen entsprechen</title>
		<author>
			<persName><forename type="first">H</forename><surname>Helmholtz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Angew. Math</title>
		<imprint>
			<biblScope unit="volume">1858</biblScope>
			<biblScope unit="page" from="25" to="55" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Teukolsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Vetterling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Flannery</surname></persName>
		</author>
		<title level="m">Numerical Recipes: The Art of Scientific Computing</title>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Generalized gradient approximation made simple</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Perdew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ernzerhof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="3865" to="3868" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Accurate molecular Van Der Waals interactions from ground-state electron density and free-atom reference data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tkatchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scheffler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page">73005</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Python interface for ab initio path integral molecular dynamics simulations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ceriotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>More</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Manolopoulos</surname></persName>
		</author>
		<author>
			<persName><surname>Pi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Phys. Commun</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="1019" to="1026" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Modeling quantum nuclei with perturbed path integral molecular dynamics</title>
		<author>
			<persName><forename type="first">I</forename><surname>Poltavsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tkatchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chem. Sci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1368" to="1372" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<title level="m">Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Finding density functionals with machine learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page">253002</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Nonlinear gradient denoising: Finding accurate extrema from inaccurate functional derivatives</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Quantum Chem</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="1102" to="1114" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Nonlinear component analysis as a kernel eigenvalue problem</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">1299</biblScope>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Input space versus feature space in kernel-based methods</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Knirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ratsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1000" to="1017" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An introduction to kernel-based learning algorithms</title>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rätsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tsuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="181" to="201" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
