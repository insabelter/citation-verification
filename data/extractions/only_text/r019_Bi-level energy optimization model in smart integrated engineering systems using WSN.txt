Introduction
Fuzzy relational algebra, which was developed by E. Sanchez in the 1970s, has been a prominent part of medical research for over three decades. In addition to equations and inequalities, fuzzy relation systems, which embed both, have proven effective in numerous practical contexts, including fuzzy inference systems, texture analysis and reconstruction, clinical issues, knowledge engineering, three-tier streaming media systems based on the HTTP protocol, P2P computer networks, and Bit torrent-like P2P network systems  (Wu and Guu, 2004) . There are two major research themes in fuzzy relational systems: The first research objective is to resolve a fuzzy relation system with a specific composition  (Qiu et al., 2020) . It demonstrates that it is the bedrock of the majority of relevant research. The second area of research is fuzzy relation optimization problems, which have a fuzzy relation system as a constraint  (Yang et al., 2016) . Fuzzy relation optimization challenges frequently rely on a number of management objectives and needs to create their objective functions. Single-level objective problems are the majority of the optimization problems with a constraint on a fuzzy relational system. Additionally, system administrators may have additional requirements that must be taken into consideration when single-level optimization is employed.  Yang et al. examined  single-level min-max programming using a BT-P2P file-sharing system  (Rastogi et al., 2015; Bulanov et al., 2004) .  Guu et al. developed  bi-level optimization to achieve a balance of realistic management requirements  (Bjorklund et al., 2003; Pedrycz, 1985) . As per further explored difficult managerial requirements by creating a three-tiered optimization problem for the firm  (Stamou and Tzafestas, 2001; Shieh, 2007) . Their solution for bilevel optimization with max-product fuzzy relation inequalities included wireless communication. The goals' aspects allow for both management qualities. Fairness was applied to the wireless communication station system. Growing numbers of individuals utilize wireless communication. Signals, data, and information are delivered by fixed emission basic stations. Start from the premise to n EBSs, for example, A 1 , A 2 , . . .. An (see Fig.  1 )  (Markovskii, 2005) . The jth EBS will emit a high-intensity electromagnetic wave x j > 0, j = 1, 2, . . . , n. The channel of interaction determines the intensity of electromagnetic waves  (Bi et al., 2014) . B 1 , B 2 , . . . .B m testing points are required at each location to guarantee the communication quality criteria is chosen to measure the electromagnetic radiation's intensity (see Fig.  1 )  (Lin and Yang, 2020) . The amount of electromagnetic radiation released by a substance A j is denoted by a ij x j at the ith testing point B i  (Yang et al., 2015) . It must be assumed that at B i , minimal quality of communication is required is b i (bi > 0). Reduced all parameters to a unit interval [0, 1] and explained the model with the help of fuzzy relations  (Guu and Wu, 2019) . a m1 x 1 Va m2 x 2 V . . . Va mn x n≥ bm} (1) {a 11 x 1 Va 12 x 2 V . . . Va 1n x n≥ b 1 a 21 x 1 Va 22 x 2 V . . . Va 2n x n≥ b2 . . . A • Tx T T ≥ Tb T (2) where A = (a ij ) (m×n) ∈ [0, 1] m×n , x = (x 1 , x 2 , . . . , x n ) ∈ [0, 1] n , b = (b 1 , b 2 , . . . ., b m ) ∈ [0, 1] m , and • denote the composition of the maximum product  (Sofi et al., 2015) . Many people agree that the human body is negatively impacted by electromagnetic waves. To restrict or eliminate the negative effects of electromagnetic fields on the human body, it is critical to keep both the system performance and the strength of the electromagnetic radiation the same. Variable x(x 1 , = x 2 , x 3 , x 4 . . . x n ) can play a significant role because of this  (Guu et al., 2017) . Therefore, we should try to lower the intensity of electromagnetic fields, the variables that meet the system (1). To address this, the team of Yang et al. discovered a latticed linear programming as follows: min z i (x) = x 1 ∨ x 2 ∨ x 3 . . . x n s.t Aox T ≥ b T By reducing the need to seek all minimal approaches to the limitation system, this novel approach saved the researchers time (1). X 1 (A, b) includes the following: The primary purpose of (3) is to maintain the maximum quantity of radiation while keeping the quantity at a minimal. A systems analyst must keep in mind that excessive energy output could harm the human body. Even still, Theorem 4 in Section 3) shows that there are no unique optimal solutions to Problem (3). X 1 (A, b) is an infinite set of optimum solution to Problem (3), sometimes known as X 1 (A, b). As a result, we use an unlimited set of X 1 (A, b) values to look for the most ideal solution, which employs a second optimization objective  (Shang et al., 2014) . In the above definition, optimizing the second objective given X 1 (A, b). Constraint reuse is a secondlevel issue. To increase non-operational base stations, we must reduce operational base stations. When base stations fail, their maintenance costs fall. The second goal is to reduce base station operating costs. While a non-functional base station has no electro-magnetic strength, a functional base station does. For instance, in order to keep the zero norm of the vector x = (x 1 , x 2 , x 3 , x 4 . . . x n ) at the lowest possible level, one must not deploy additional base stations  (Alcalá-Fdez and Alonso, 2015) . It is the number of non-zero elements in x, such as x 0 . ∥x∥ 0 = |{i|x i ̸ = 0, 1 ≤ i ≤ n}| Due to this, the second objective is changed to be the min ∥x∥ 0 value. This difficulty is described as follows: min ∥x∥ 0 s.t x ∈ X 1 (A, b) By combining the first and second level issues, we obtain  (Morshedy et al., 2019) . min z 1 (x) = x 1 ∨ x 2 ∨ x 3 ∨ x 4 • • • ∨ x n - (3) s.t Aox T ≥ b T , min z 2 (x) = ∥x∥ 0 , s.t x ∈ X 1 (A, b) (4) Problem-solving solutions are compiled through a process called X 1 (A, b) (3). Aim 1 in Problems (3)-(  4 ) is to keep electromagnetic waves intensity as low as possible, whereas objective 2 is to keep base station operating expenses as low as possible. Problem (3) can be solved using the idea of a minimal solution matrix presented by Yang et al. While Yang's method fails to provide the whole solution set to the problem, this paper will prove that (3). We could not employ Yang's methods in the original study since it did not address the bi-level problem. This study seeks to discover the best possible solution to the problem stated above, which is bi-level objective programming (3), (4). The final section of Section 3 looks at the ideal solution set for Problem (3) and measures its quality by utilizing a minimum-maximum norm solution matrix. This chapter studies the problem at the second level (4). We use the set of minimum-norm solutions to solve the problem (4). We have included a mathematical example in Section 5 to show how and why our proposed method might be implemented and would produce accurate results. Section 4 discusses several forms of management requirements in order to highlight multiple kinds of bi-level difficulties.

Yang's method for first level problems
The optimal solution to the issue addressed in this Section 3. Specifically, Yang's method can only be utilized to discover a limited number of optimum solutions to the given problem (3). While it is true that, in some situations, the set of any and all efficient outcomes to Problem (3) is not a convex infinite set, it is possible for some non-convex solutions to exist, too. Yang's method has the unfortunate property of being unable to uncover all potential answers to the problem (3). Also, it has little to no effect on the bi-level problem (3)-(4).

Yang's problem-solving method is based on the matrix of minimal solutions
∀x = (x 1 , x 2 , x 3 , x 4 , . . . x n ) ∈ [0, 1] n which denotes mas norm -∥x∥ ∞ = max 1≤j≤n x j = x 1 ∨ x 2 ∨ x 3 ∨ • • • ∨ x n where ∥x∥ ∞ Consider the set X (A, b) be the sum of all system (1) solutions, i.e. X (A, b) = x ∈ [0, 1] n |A • x T ≥ b T If so, the best solution set for Problem (3) is X (A, b). X (A, b) = x 1 * ∈ X (A, b)|∥x 1 * ∥ ∞ , ∀x ∈ X (A, b) As per Discrimination Matrix definition  (Loetamonphong and Fang, 1999 ) ∀1 ≤ i ≤ m, 1 ≤ j ≤ n, gives d ij = x = { b i a ij }, if a ij ≥ b i , 0, if a ij < b i (5) The system's discrimination matrix is known as D = (d ij ) m×n . Theorem 1. x must be a vector whose components are {1, 1, 1 . . . 1}. For system (1), each column of the discrimination matrix D must contain a nonzero  (Shieh, 2008) . The solution matrix D = (d ij ) m×n for the system. The system's solution matrix is S = (S ij ) where S ij is in the set {0, d ij }. Theorem 2. If S = (S ij ) m×n is a solution to the system, then S = (s 1 , s 2 , s 3 , s 4 , . . . , s n ). When the vector was considered. X S = (∥S T 1 ∥ ∞ , ∥S T 2 ∥ ∞ , ∥S T 3 ∥ ∞ , ∥S T 4 ∥ ∞ , . . . ∥S T n ∥ ∞ ), = ∨ m i=1 S i1 , ∨ m i=1 S i2 , ∨ m i=1 S i3 , ∨ m i=1 S i4 , . . . , ∨ m i=1 S in , is the solution. If S = (S ij ) m×n The system's solution matrix. X S = ∨ m i=1 S i1 , ∨ m i=1 S i2 , ∨ m i=1 S i3 , ∨ m i=1 S i4 , . . . , ∨ m i=1 S in , (6) The end result is a matrix solution of system (1) from S. Lemma 1. A solution matrix S exists for (1) , S = x i.e. X S ≤ x, ∀1 ≤ i ≤ m. Let, r i = min 1≤j≤n {d ij |d ij ̸ = 0}, (7) R i = {j|d ij = r i , 1 ≤ j ≤ n}. (8) The significant definition in this part is a minimum matrix. The lowest solution matrices (1) is a matrix S m = (S m ij ) that has these properties: S m a system solution matrix (1)  (Yang et al., 2015) . ∀j / ∈ R i , S m ij = 0. Additional claims state that S m is the smallest basic matrix solution to X S m . Theorem 3 asserts that if system (1) has (i.e. S m ), then X S m is the corresponding minimal solution to problem (3). The system minimal solution matrix is denoted as MSM = S m . X ms (A, b) = {X s m |S m ∈ MSM}. By Yang's method, only specific solutions of Problem (3) can be found, that is, X S m (A, b). A second look at the set X S m (A, b), which Yang's approach obtains, as seen below. So for Problem (3), X S m (A, b) might not equal to X 1 (A, b). As Theorem 3 claims, there is a unique solution to Problem X s ∈ X ms (A, b) when X s is the best possible solution (3). It is possible, but this is still only an optimization approach that does not guarantee that a solution is optimal (4)  (Luoh and Liaw, 2010) . We cannot solve Problem (3) to (4) as it is (A, b). Thus, X S m is not the best solution (11) (or: it is not the optimal solution)? X ms (A, b) ̸ = X 1 (A, b).

Problems with minimum-maximum norm solution matrices (3)
On the other side, in this part, we explore the best collection of Problem solutions (3) (which we denote as X 1 (A, b))  (Fang and Li, 1999) .

Multiple norm solution matrix
A consistent system (1) implies an optimal solution to problem (3)  (Bělohlávek et al., 2017) . r max-min = max 1≤i≤m r i = max 1≤i≤m min 1≤j≤n {d ij |d ij ̸ = 0} (9) One final conclusion to draw is that you can use Theorem 3 as well as the notion of minimal solution matrix to evaluate whether or not an argument is correct  (Anderson, 1974) . If a system is constant, the optimal solution to the issue is reached. x1 * = (r max-min , r max-min , r max-min , . . . , r max-min ). (10) Based on the theorem, x 1 * = x 1 * 1 , x 1 * 2 , x 1 * 3 , . . . .x 1 * n is a solution to problem X. (3). The only way to resolve the problem is to find a solution (3). Next, we solve for x 1 * 1 ∨ x 1 * 2 ∨ x 1 * 3 ∨ • • • x 1 * n = r max-min in the following system (1). So, ∀1 ≤ j ≤ n, x 1 * j ≤ r max-min , which is addressed as x 1 * ≤ x1 * . (11) Accordingly, x1 * = (r max-min , r max-min , r max-min . . . r max-min ) is also a solution to the problem in question, which means that an acceptable solution to that problem can be found. Finally, we can conclude that x1 * 1 ∨ x1 * 2 ∨ x1 * 3 ∨ • • • ∨ x1 * n = r max-min When these elements are merged, the result is the best solution to the issue (3). Finally, using the value r max-min : The smallest and the maximum-norm discrimination matrix is shown in Eq. (  11 ). D can be modelled as a discrimination matrix (1). Matrix with cross products of vectors t ij = d ij d ij ≤ r max-min , 0, otherwise. system (1) has a minimum maximum-norm discrimination matrix whose elements are m × n. Matrix T can be computed from D as follows: Replace all the entries d ij with zero, if d ij > r max-min . Assume system (1) is complete. In this matrix, D is not zero. After constructing the minimum-maximum norm discrimination matrix, it is possible to check for nonzero elements. The matrix storing the answer to the minimum maximal norm. T is the system's highest mean-square difference discriminating matrix (1). In matrix T = (t ij ) m×n , t ij can have the values 0, t ij , but if there exists a unique ji ∈ {1, 2, 3, 4, . . . , n} such that t ij = 0, then T is a matrix having a minimal maximum norm ∀1 ≤ i ≤ m, t ij = t ij ̸ = 0. Also, T is a solution matrix. According to the preceding theorem, let T = (t ij ) m×n be the system's solution matrix (1). A solution matrix must be at least as big as the biggest ∀1 ≤ i ≤ m and 1 ≤ j ≤ n such that t ij ≤ r max-min holds. If system (1) is valid, the lowest absolute maximum solution matrix (or minimum). A minimum-maximum norm matrix solution T = (t ij ) m×n for each system's lower-maximum-norm (1). As the system's corresponding solution X T = ∨ m i≤i≤m t i1 , ∨ m i≤i≤m t i2 , ∨ m i≤i≤m t i3 , ∨ m i≤i≤m t i4 , . . . , ∨ m i≤i≤m t in is considered a min-max norm matrix solution, it is called a minimum-maximum norm matrix solution (1). We use MMNS = T |T is a minimum-maximum norm solution matrix of (1) and X mmns (A, b) = X T  |T ∈ MMNS for the system (1). When solving a system, all possible min-max norm matrix solutions are simply X mmns  (A, b) . Therefore X mmns (A, b) ̸ = ∅.

Optimal solution set of problem
We summaries the solution set for problem (3) here, and so the above mentioned set X mmns is it (A, b). Problem (3) is best solved if system (1) is consistent.X 1 = ∪ x∈Xmmns(A,b) [x, x1 * ]. Collects all matrices with a minimal maximum norm X mmns provides the best results), the optimal value is r max-min . Therefore, we have y 1 ∨ y 2 ∨ y 3 ∨ y 4 • • • ∨ y n ≥ r max-min Also, y ≤ x1 * provides y 1 ∨ y 2 ∨ y 3 ∨ y 4 • • • ∨ y n ≥ r max-min Alternatively, y ∈ X 1 (A, b) indicates the concept of y j ≤ r max-min , ∀1 ≤ j ≤ n. y 1 ∨ y 2 ∨ y 3 ∨ y 4 • • • ∨ y n = r max-min seeking effort to benefit y 1 ≤ r max-min , ∀1 ≤ j ≤ n. A consequence of this is that y ≤ x1 * is an optimum solution to Problem (3), y ∈ X (A, b). Furthermore, we demonstrate that X 1 (A, b) ⊆ ∪ x∈Xmmns(A,b) [x, x1 * ]. Find the most ideal solution for problem y ∈ X (A, b) (3). Similarly, Theorem 2 asserts that if y is an element of X (A, b), then there is a T such that x T ≤ y i.e ∨ 1≤i≤m t ij ≤ y j , ∀1 ≤ j ≤ n, it follows that t ij ≤ r max-min , ∀ 1 ≤ i ≤ m, 1 ≤ j ≤ n. T is the system's minimum-maximum-norm solution matrix (1). As a result, X T result, the solution with the lowest max-norm matrix is not unique.

The solution to the bilevel problem (3)-(4)
The purpose of this part is to build an efficient approach for finding the optimal solution to our suggested bi-level Problem (3)-(  4 ). Indeed, Problems (3)-(  4 ) are virtually the same as the subsequent second-level Problem (4), min z 2 (x) = ∥x∥ 0 , s.t x ∈ X 1 (A, b) (A) Theorem 4 proves that the feasible domain, in the majority of cases, i.e. X 1 (A, b) is an infinite yet non-convex set. Additionally, the objective function Z 2 (x) = ∥x∥ 0 is nonlinear and expressible implicitly. As a result, solving Problem (4) directly is challenging. The fourth issue is transformed into a discrete optimization problem min z 2 (x) = ∥x∥ 0 , s.t x ∈ X mmns  (A, b) . Take note that the feasible domain in Problem (A), namely X mmns (A, b), a set of things A conventional branch-and-bound strategy or MATLAB's complex mathematical abilities may be used to tackle this 0-1 integer programming issue. Let T = (t ij ) m×n be the system's minimum-maximum-norm discriminating matrix (1). The index sets {J i |i ∈ I} are defined as J i = {j|t ij ̸ = 0, j ∈ J} (B) where I = {1, 2, 3, . . . , m} and J = {1, 2, 3, . . . , n}. On the basis of the index sets {J i |i ∈ I} acquired previously, we design the following 0-1 integer programming min n ∑ j=1 max 1≤i≤m f ij , s.t n ∑ j=1 f ij = 1, ∀1 ≤ i ≤ m, f ij = 0 or 1, ∀1 ≤ i ≤ m, 1 ≤ j ≤ n, f ij = 0, ∀i, j with j / ∈ J i . (C) Problem (4) (C). A C-solution problem is an efficient solution to issues with optimal solution characteristics, as shown in proofs 6 and 7. The single equations for the above two multi-variable problems are identical; in other words, the multi-variable problems (C) (which can be solved using division method or other standard mathematical software) and the zero-to-one integer linear programming difficulties are correspondingly lowered to one single problem: problem (C).

Relationship between (4) and (A)
This indicates that if XT is the optimal solution for A, it is also optimal for B. Proof. Assume X T * ∈ x mmns  (A, b) , where T * ⊆ MMNS is a matrix of minimum max-norm solutions. (Feasibility) As a result of Theorem 4, X T * ∈ x mmns (A, b) ⊆ X 1 (A, b). Assume that y ∈ X 1 (A, b) is a possible option (4). X 1 (A, b) = ∪ x∈Xmmns(A,b) [x, x1 * ]. There exists a function X T * ∈ x mmns (A, b) such that X T ≤ y ≤ x1 * denotes ∥x T * ∥0 ≤ ∥y∥ 0 . We have ∥x T * ∥0 ≤ ∥x T ∥ 0 because X T * ∈ x mmns (A, b ) is a possible solution to the problem and ideal answer. Inequalities contribute to the value of ∥y∥0 ≤ ∥x T * ∥ 0 .

Relationship between (A) and (C)
Assign the feasible domain of Problem (C) to the symbol X (f ). Bear in mind that MMNS denotes the collection ∀ system's minimum maximum norm solution matrix (1). Now, we will establish a correspondence between X (f ) and MMNS. ψ : MMNS → X (f ), T → f T where T = (t ij ) m×n is an arbitrarily large minimum-maximumnorm solution matrix, and f T is a matrix representing {f T ij |i ∈ I, j ∈ J}, f T ij = {1 if t ij ̸ = 0} 0 if t ij = 0 Checking if f T is a plausible solution to Problem (C) is easy, i.e. f T ∈ X (f ). Additionally, the mapping ψ the sets are linked one-to-one, MMNS and X (f ) mapping towards ψ -1 : X (f ) → MMNS, f → T f (H) where f = {f ij |i ∈ I, j ∈ J} is an arbitrary feasible solution to the issue (C) and T f = (t ij ) m×n with (t ij ) f = {t ij if f -ij = 1, }0 otherwise. (I) Theorem 3. Assume that f = X (f )T = (t ij ) m×n ∈ MMNS is an arbitrary minimum maximum norm solution matrix. Let f ∈ X (f ) provide a potential answer to the problem (C). Then there is ∥X T ∥ 0 = n ∑ j=1 min 1≤i≤m f ij (J) where X T is the solution to T . X T = ∨ m i∈I t i1 , ∨ m i∈I t i2 , ∨ m i∈I t i3 , ∨ m i∈I t i4 , . . . , ∨ m i∈I t in Given that f is a realistic solution to problem (C), implies that f ij = 0 or 1, ∀i ∈ I, j ∈ J. This implies ∨ i∈I f ij = 0 or 1, ∀j ∈ J, as |{j ∈ J| ∨ i∈I f ij = 1}| = ∑ j∈J (∨ i∈I f ij ), it has ∥X T ∥ 0 = |{j ∈ J| ∨ i∈I t ij ̸ = 0}| = |{j ∈ J| ∨ i∈I f ij = 1}| = ∑ j∈J ∨ i∈I f ij = n ∑ j∈J max 1≤i≤m f ij (K) Theorem 4. If f * is the best solution (C) and T * = ψ(f * ) = (t ij ) m×n is the minimum maximal norm solution matrix, then X T * = ∨ i∈I t * i1 , ∨ i∈I t * i2 , ∨ i∈I t * i3 , ∨ i∈I t * i4 , . . . , ∨ * i∈I t * in an ideal answer to the issue (A). Given that T * a matrix having a minimal max-norm solution, X T * ∈ X mmns (A, b) is a matrix solution with the smallest maximum norm, i.e. (A). Let X T * ∈ X mmns (A, b) denote any possible solution to Problem (A), with T denotes the minimum max-norm quantitative approach. Assume that f = ψ -1 (T ) is an acceptable solution to Problem (C) that matches T . On the other hand, f * denotes the answer to T * . According to Theorem 3, {∥X T ∥ 0 } = n ∑ j=1 max 1≤i≤m f ij , ∥X T ∥ 0 = n ∑ j=1 max 1≤i≤m f * ij , (L) Additionally, because f * is the optimal solution to Problem (C) and f is a viable solution, ∑ n j=1 max 1≤i≤m f ij ≥ ∑ n j=1 max 1≤i≤m f * ij -M holds. In light of (L), we have z 2 (x T ) = ∥X T ∥ 0 = n ∑ j=1 max 1≤i≤m f ij ≥ n ∑ j=1 max 1≤i≤m f * ij = ∥X T * ∥ 0 = z 2 (x T * ) (N) 4.3. Algorithm for optimal solution of problem (3)-(  4 ) Because of the information provided in the previous section, here is a well-performing solution for addressing Problems (3)-(  4 ) in this paragraph. As a means of addressing issues (3) to begin with, there was an Initial Algorithm developed (4). Step-1: Utilize Theorem 1 to determine the consistency of system (1). If Aox T ≥ b is true, where x = (1 * , 1 * , 1 * , . . . , 1). Otherwise, system (1) will fail to solve the problem and will terminate. Step-2: compute the system (1)'s discrimination matrix D = (d ij ) m×n . Step-3: ∀1 ≤ i ≤ m, the computer r i by(  7 ), i.e. r i = min 1≤j≤n {d ij |d ij ̸ = 0}. Step-4. Divide Problem (3) by (  14 ) to obtain the ideal value r max-min i.e. Step-5: Determine the system (1)'s minimal maximum-norm discrimination matrix T = (t ij ) m×n . Step-6. ∀1 ≤ i ≤ m, calculate the index set j 1 using the formula (B), i.e. J i = {j|t ij ̸ = 0, 1 ≤ j ≤ n}. Step-7. Integer Programming Issue 0-1 Using (C), i.e. min ∑ n 1≤i≤m f ij s.t n ∑ j=1 f ij = 1, ∀1 ≤ i ≤ m, f ij = 0 or 1, ∀1 ≤ i ≤ m, 1 ≤ j ≤ m, f ij = 0, ∀i, j with j / ∈ J i . Solve Problem (C) using branch-and-bound, f ij or1, ∀1 ≤ i ≤ m, 1 ≤ j ≤ m, Step 9. Construct the matrix T = (t ij ) m×n with respect to f ij , where t ij is defined by (I). Assume that T equals The vector X T = (∥T T 1 ∥ ∞ , ∥T T 2 ∥ ∞ , ∥T T 3 ∥ ∞ , ∥T T 4 ∥ ∞ , . . . ∥T T n ∥ ∞ ), thus, is the best solution to Problem (3)-(4). • Complexity of computation in which n is variable number; m is the inequality numbers. |J i |: index set j i , 1 ≤ i ≤ m; k = ∏ m i=1 |J i | index set J 1 × J 2 × J 3 , . . . × J m . Algorithm 1's initial step requires mn operations in order to check for consistency in system (1). The matrix D is computed in step 2 in 2mn operations. Step 3 incurs a cost of 2m(n -1). Calculating the best value r max-min in Step 4 requires m -1 operations due to the previously acquired r i |1 ≤ i ≤ m. Both Steps 5 and 6 are cost-effective in terms of operations. Steps 7 and 8 require (k -1)(m -1)(n -1)n branch and bind operations to get the best solution. The 9 th and 10th steps each cost mn and (m -1)n operations. As a result, each step in Algorithm 1 requires mn + 2mn + 2m(n -1) + (m -1) + mn + mn + (k -1)(m -1)(n - 1)n + mn + (m -1)n = (k -1)(m -1)(n -1)n + 9mn -m -n -1 operations. O is the complexity of computation (kmn 2 ).

Generalize the second-level problem's objective function
To slow the rise of cellular computing, we require a bi-level programming problem that confronts max-product fuzzy similarity inequality. Indeed, we can use different objective functions z 2 (x) to explain additional management requirements. The various levels in a linear program could include one of two approaches: In other words, the second level's optimization problem (also known as the objective function z 1 (x) may be thought of as a monotone increasing function. Thus, (also known as the objective function) satisfies if z 2 (x) z 2 (y). By offering the above general Bilevel Programming Challenges, we are sufficient to facilitate a wider range of management requirements. (I) ↦ → min z 1 (x) = ∥x∥ ∞ s.t A • x ≥ b (II) ↦ → min z 1 (x)s.t x ∈ X i (A, b), where X i (A, b) Proof. Let us assume that z 2 (x) is an increasing monotone functionality. If system (1) is stable, a min maximum-norm function exists. T system (1) has a correlational design that is consistent with it X T is the best answer to I-II. Previous proofs states that for any S ∈ H, X S a good answer to Problem I i.e., ∥X S ∥ ∞ = min x∈X (A,b) ∥x∥ ∞ = r max-min , where H denotes minimal max-norm solution matrices (1). As a result, there exists a T ∈ H such that z 2 (x T ) = min s∈H z 2 (x s ). To conclude the proof, we must verify that ∀, z 2 (x T ) ≤ z 2 (x). Assume x ∈ X 1 (A, b). According to Lemma 1, there exists a solution matrix S = (S ij ) m×n according to Lemma 1. Take note of the fact that X-INFY As a result, ∥X s ∥ ∞ = ∥x∥ ∞ . That is max 1≤i≤m min 1≤i≤n S ij = r max-min , which means that S is a matrix with a minimum max-norm solution, i.e. S ∈ H. Additionally, because z 2 (x) is a monotone rising function, z 2 (x S ) ≤ z 2 (x). As a result, z 2 (x T ) = min s∈H z 2 (x s ) ≤ z 2 (x S ) ≤ z 2 (x). So, X T is the best solution to Problems I-II. Algorithm number two is a two-step process. Algorithm 1's steps 1 through 6 and 8 through 10 are identical, step-7. min z 2 ( max 1≤i≤m d i1 f i1 , max 1≤i≤m d i2 f i2 , max 1≤i≤m d i3 f i3 , max 1≤i≤m d i4 f i4 . . . max 1≤i≤m d in f in ) s.t n ∑ j=1 f ij = 1, ∀1 ≤ i ≤ m, f ij = 0 or 1, ∀1 ≤ i ≤ m, 1 ≤ j ≤ n, f ij = 0, ∀i, j with j / ∈ J i . is used to define the 0-1 integer programmer.

Comparison to previous works
There appears to be only one layer of optimization that deals with fuzzy relational systems, as far as we know. Another way of thinking about this is for instance by looking at a study done by A.A. Molar et al. where they assessed the fuzzy relation optimization problem using four different features: linear, quadratic, geometric, and minimum-maximum. Lee and Guu, together with Fang et al. studied fuzzy relational simplex method, which utilizes max-min composing, as well as all the related research by and about these individuals. Using branch-and-bound strategy, they addressed their stated challenge. The results were tested using addition-min fuzzy relations. Solve the problem with a single variable and an ideal answer. Each of the problems below has a single-level optimization challenge. However, it adds a segment goal function. min z 2 (x) = ∥x∥ 0 . where ∥x∥ 0 denotes the vector x zero-norm, To our knowledge, the connection has still not been put into the fuzzy set. The zeronorm optimal solution is suitable, and our suggested resolution algorithm has shown that it is realizable in application settings.

Conclusion
To better comprehend management ideas for wireless transmission station systems. Finding a monotonic rising function that suggests superior management is actually level two optimization. In the first level of lattice-preserving linear equations, optimal solutions are difficult to discover. The limited systems domain is valid, but not the domain of first-level lattice linear programming. We solve second-order programming problems using mini-norm and max-norm matrices. These solutions are included in the minimal matrix paradigm. To solve our 0-1 issue, we used the standard branch-and-bound strategy. Our bi-level positions also provide extensive replies. The traditional Max-T mixture is the well-known Max-product. The classical composition is updated using a fuzzy relation approach. In future investigations, we are particularly interested in bi-level optimization and compositions like min-product, respects, and bipolar Max-T.