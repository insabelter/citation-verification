Skin grafting has been employed for centuries.1
There are several reasons to graft wounds that are able to heal. For example, burns are generally grafted with split-thickness grafts to speed healing, and full- thickness grafts are used after large facial excisions to prevent contraction. In nonhealing wounds, the basis for the efficacy of grafting is puzzling. Why epithelium at the edge of nonhealing wounds is "unable" to cover these wounds, but epithelium from grafts, even meshed partial-thickness grafts, is able to migrate and cover the same wounds is a long-standing unanswered bio¬ logic question. Recently, information concerning the fate of cultured epithelial allografts has allowed us to hypothesize about how skin grafts work in healing chronic wounds. It has been learned that the success of cultured epithe¬ lial allografts appears to be due to a potent stimulus to healing provided by these grafts. We suggest, in a sim¬ ilar fashion, that autografts may work not only by re¬ placing tissue but also as a pharmacologie agent stim¬ ulating wound closure. Over the past decade, cells grown in the laboratory through tissue culture techniques have been used to treat acute and chronic wounds. In 1981, O'Conner et al2 published the first data on the use of cultured expanded autologous (derived from self) epithelial cell sheets in the treatment of large wounds in burn patients. This event heralded the beginning of using cultured cells as skin grafts. However, the idea for us¬ ing sheets of cultured cells for grafting may have begun many years earlier. In 1907, Harrison, a biologist, showed that individual cells were capable of life outside the body in which they had grown,3 and, by the middle of this century, epithelial and epidermal cells had been grown in culture. Pickerill,3 with extreme foresight, crystallized the idea of cultured skin grafts in 1951. In discussing the possibility of skin banks, he stated the following: "It is envisaged that the sheet of nylon and attached cells would be handled and stored as one for refrigeration and transport, and that when being used for grafting the cell-coated nylon would be applied as a graft-cum-dressing, cell surface downwards, and a pressure dressing placed on top." Green and col¬ leagues4 in 1979 showed that epidermal cells grown in vitro could be stratified into layers and were able to be transplanted as a graft onto a wound. Accepted for publication January 4, 1993. From the Department of Dermatology and Cutaneous Surgery, University of Miami (Fla) School of Medicine. Reprint requests to Department of Dermatology and Cutaneous Surgery, University of Miami School of Medicine,  PO Box 016250  (R-250), Miami, FL 33136 (Dr Falanga). Since the work of O'Conner and colleagues, cultured autografts (derived from self) and allografts (derived from a donor of the same species) have been successful in the treatment of both acute and chronic wounds. Hefton et al,5 in 1983, successfully grafted burn pa¬ tients with cultured allografts for the first time. First, Leigh and coworkers6,7 and then Phillips and cowork- ers8 successfully treated refractory chronic leg ulcér¬ ations with cultured epithelial autografts and al¬ lografts. Since then, cultured epidermal cells have been used for many purposes.911 It is not difficult to conceptualize how cultured autologous grafts work, using one's own cells that are expanded in vitro and transplanted as a graft onto a wound. However, the reason why cultured allografts (cells from a donor) are successful may be more difficult to envision. One might logically assume that allografts would be rejected as foreign by the body. In practice, however, cultured epithelial allografts appeared to survive and are successful in the treatment of chronic wounds. The fact that human epidermal cells grown in culture lose all expression of HLA-DR antigens12 and no longer contain Langerhans cells13 seemed to explain why allografts would take. By losing these markers generally associated with transplantation rejection, it was believed that cultured allografts survived grafting. However, in 1987 Gielen and colleagues14 presented data that began to shed new light on the true fate of cultured epithelial allografts. Utilizing anti-MHC class 1 antigen monoclonal antibodies directed against epi¬ thelial cells, they found, 6 months after grafting, that keratinocytes present at the previously grafted areas were from the recipient and not from the donor. For the first time, this implied that the donor allografts did not have prolonged transplantation survival as had been originally proposed. Other reports confirmed this.  15, 16  Two separate groups,17,18 both in 1989, found, using sex-mismatched donors and recipients and probes spe¬ cific for Y chromosomes, that eventually all of the ke¬ ratinocytes in the previously grafted areas were from the recipient and none were from the sex-mismatched donor. In fact, in over 95% of cases the absence of do¬ nor cells in the reepithelialized ulcers were seen as early as 1 week after grafting. Thus, cultured allografts do not ultimately survive transplantation. However, they do seem able to pro¬ vide a potent stimulus to healing when placed on a wound. Interestingly, in chronic wounds previously refractory to treatment, the use of cultured kerati- nocyte allografts causes rapid healing even in the face of graft failure. Leigh and coworkers6 felt that host reepithelialization seen after allografting was caused by soluble "growth factors," and this was clinically ap¬ parent by "an effect on the edge of the ulcer which starts to grow in rapidly."6 Other authors8,19 have noted this so-called edge effect, and some have also ex¬ pressed the idea that the epithelial cells elaborate growth factors responsible for the rapid reepithelial¬ ization of the wounds.20,21 If, as it appears, growth fac¬ tors are in some way responsible for the rapid healing of chronic ulcers after cultured epithelial allografting, then perhaps "dosing" of these growth factors with re- peated grafts may be important. Toward that end, Beele and coworkers22 were recently successful in treating chronic leg ulcers with repeated cultured epi¬ dermal allografts, suggesting that repeated "doses" are needed in some patients to aid in wound healing. They noted healing from the edge with each successive graft. It is possible that traditional skin grafting using the patient's own skin without in vitro expansion may work, in part, due to growth factors supplied by the patient's own healthy donor skin. The donor skin transplanted to a nonhealing chronic wound may bring with it factors or the capacity to elaborate factors ab¬ sent or deficient in the recipient area. Possibly, the stratum corneum, which is known to act as a reser¬ voir,23 or other cells in the grafted tissue, may act as a transport for needed endogenous "growth factors." It is well known that acute wounds produce growth fac¬ tors that stimulate healing.24 These factors supplied by the newly grafted skin may significantly contribute to the eventual healing of the wound. In addition, the newly grafted skin may serve to stimulate matrix for¬ mation or the release of inflammatory mediators. Most grafting techniques (pinch grafting or mesh grafting) do not cover all of the ulcer to conserve donor tissue. A continued stimulus for reepithelialization is required to resurface the remainder of the ulcer and is likely provided by the newly transplanted skin. This is con¬ sistent with previous observations made with regard to skin grafting. O'Donoghue and Zarem25 showed that free skin grafts become vascularized, suggesting that the grafted tissue causes host blood vessels to grow into the graft. They also noted that fresh grafts are more efficient at attracting blood vessels than frozen- thawed grafts, suggesting a donor-dependent process. It appears that the donor tissue is responsible for bringing with it an angiogenesis factor. Grafts taken from highly vascular donor sites heal better than those taken from sites with relatively poor vascular supply, once again suggesting a donor-dependent process.26 Recently, in work done on pigs, whose skin is histologically similar to human skin, Blair and coworkers27 found that using "diced" skin grafts were as effective in healing large wounds as mesh grafting.27 This is in¬ teresting because, when using "diced" grafts, their ori¬ entation is lost (ie, epidermis up or down). Similarly, in microskin grafting used in China, orientation of the autografts may be lost without affecting the clinical outcome.28,29 Perhaps donor skin carries with it a "dose pack" of factors that are released whether the graft takes or even if it is upside down. Gilmore and Wheeland30 observed that several patients who had partial healing of chronic venous ulcérations after a single skin graft healed completely with additional grafting treatments. These results may also be ex¬ plained by the "dose pack" idea. These patients may have needed additional "doses" of skin grafts (and their presumed factors) to effect complete healing and ex¬ plains why for chronic wounds single skin grafting is inferior to multiple grafting sessions. That is, chronic wounds may lack certain factors that acute wounds possess and may require several "doses" of skin graft¬ ing. Besides "dosing" skin grafts, it may also be possi-ble, someday, to augment the stimulatory properties of donor skin. Perhaps pretreatment of the donor skin prior to harvesting or, perhaps, wounding and harvest¬ ing donor skin at variable times during the healing process may allow liberation of selected growth factors. These types of modifications of grafting techniques may eventually help to illuminate which factors are important in speeding healing of wounds and, perhaps, allow a more intelligent approach to choosing potential factors used to stimulate healing. All of which suggests that skin grafts may not only be tissue replacement but may also serve as pharmacologie agents in the treat¬ ment of chronic wounds.