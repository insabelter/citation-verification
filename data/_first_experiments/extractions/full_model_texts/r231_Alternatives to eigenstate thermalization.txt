Introduction and Summary of ETH: Consider an isolated quantum N -body system with hamiltonian Ĥ. Let |α denote an eigenstate of Ĥ with eigenvalue E α , and let Â denote a few-body observable. The eigenstate thermalization hypothesis (ETH) states that (1) the diagonal matrix elements A αα = α| Â|α change slowly with the state, with the difference between neighboring values A α+1,α+1 -A αα exponentially small in N , and (2) that the off-diagonal matrix elements A αβ = α| Â|β , α = β, are themselves exponentially small in N 
[1, 2] . ETH is suggested by various results in quantum chaos theory (in particular, Shnirelman's theorem  [3]  and Berry's random-wave conjecture  [4] ) for systems that have a chaotic classical limit. ETH has been verified numerically in a wide variety of quantum many-body systems that are sufficiently far (in parameter space) from points of integrability  [5] [6] [7] [8] , but it certainly does not hold in systems that are integrable or near integrable  [5] [6] [7] [8] [9] . Let |ψ(τ ) be the quantum state of the system at time τ , given by the evolution of some initial state |ψ I = α C α |α , |ψ(τ ) = e -i Ĥτ / |ψ I = α C α e -iEατ / |α , (1) with α |C α | 2 = 1. The energy of the system is Ē = α |C α | 2 E α , and the quantum energy uncertainty is ∆E, where (∆E) 2 = α |C α | 2 (E α -Ē) 2 . We assume that ∆E is algebraically small in N , (e.g., ∆E ∼ N -1/2 Ē), as is the case for any state of a macroscopic system that could be realistically prepared in a laboratory. (This is also true for theoretical models in which the initial state is provided by a sudden quench in Hamiltonians with short-range interactions  [5] .) The time-dependent expectation value of Â is Â(τ ) = ψ(τ )| Â|ψ(τ ) (2) = α |C α | 2 A αα + α =β C * α C β e i(Eα-E β )τ / A αβ , and the long-time average of Â(τ ) is A = lim τ →∞ 1 τ τ 0 dt Â(τ ) = α |C α | 2 A αα , (3) in the absence of degeneracies (which are not expected to occur in chaotic systems without extra symmetries  [10] ). The right-hand side of Eq. (  3 ) effectively sums |C α | 2 A αα over an energy window of width ∆E that is centered on Ē. According to ETH, A αα is approximately constant over this window. Thus, up to algebraically small corrections, the right-hand side of Eq. (  3 ) has the same value as the microcanonical average of Â over the same window, and is independent of the detailed pattern of values taken by the |C α | 2 coefficients. Thus ETH results in the equality of time averages and thermal averages for a very broad class of initial states. From ETH, each term in the second sum in Eq. (  2 ) is exponentially small in N . However, the number of terms in this sum is exponentially large, and so, if the phases line up coherently, the second sum can rival the first. If this happens at one particular time (say, τ = 0), it will fail at sufficiently large later times, as the time-dependent phases go out of alignment. This dephasing mechanism accounts for the approach to thermal equilibrium for an initially out-of-equilibrium state  [2, 5] . The Quantum Ergodic Theorem: In 1929, von Neumann proved a mathematical result which has been dubbed the quantum ergodic theorem (QET)  [11] . An exegesis of it has been given by Goldstein et al. (hereafter GLTZ)  [12] . GLTZ summarize QET, or "normal typicallity" as it has been more recently known, as follows: "for a typical finite family of commuting macroscopic observables, every initial wave function from a micro-canonical energy shell so evolves that for most times τ in the long run, the joint probability distribution of these observables obtained from |ψ(τ ) is close to their microcanonical distribution"  [12] . More specifically, QET states that Â(τ ) will be close to the microcanonical average of Â in the following sense: | Â(τ ) -Â mc | 2 < ǫ 2 Â2 mc for all but a fraction δ of times t, where the subscript mc denotes the microcanonical average over the energy window of all states with nonzero C α , and ǫ and δ are small numbers. The proof of the theorem requires that all energy eigenvalue differences E α -E β be nondegenerate, and an additional condition that is deemed "technical" by GLTZ, their Eq. (  17 ). Here we point out that this condition is equivalent to ETH. Hence, von Neumann's proof of QET relies on ETH  [13] . We follow the exposition of GLTZ, and consider the system to have a Hilbert space H with an exponentially large but finite dimension D. We focus on a single observable Â. GLTZ partition the Hilbert space into "macro-spaces" H ν , with dimension d ν . Each H ν is spanned by the eigenstates of Â with eigenvalue a in a particular range centered on a value a ν . Let Pν be the projection operator onto H ν , and consider its energy-basis matrix elements α| Pν |β . The condition that must be assumed to prove QET is that, for each ν, the offdiagonal elements (α = β) must be exponentially small, and the diagonal elements α| Pν |α must be exponentially close to f ν = d ν /D, the fraction of states in H ν  [11, 12] . We now argue that this condition is effectively equivalent to ETH. Consider the operator Âcg ≡ ν a ν Pν . This is a coarse-grained version of Â itself, which can be written as Â = a a|a a|; Âcg is the same, but with the individual values of a replaced by their average values in each macrospace. The intention of von Neumann and GLTZ is that Âcg should be indistinguishable from Â in practical experiments. Next, consider the energy-basis expectation value α| Âcg |α . Since α| Pν |α is (by the GLTZ technical condition) exponentially close to f ν , then from the definition of Âcg we get α| Âcg |α = ν a ν f ν , up to exponentially small corrections. Up to the additional small errors introduced by the coarse graining (which are assumed to be negligible), this last expression is equal to the trace of Â, which in this simplified model is to be identified with the microcanonical average of Â. This is equivalent to the ETH statement that an energybasis expectation value is equivalent to a microcanonical average. Similarly, if α| Pν |β is exponentially small for α = β, so is α| Â|β , which is the other key part of ETH  [2, 5] . Another way to phrase the equivalence is to note that both the GLTZ technical condition and ETH rely on exponential smallness of the overlap between an energy eigenstate and an eigenstate of an observable Â that exhibits thermal behavior. As already noted, ETH can be justified by various results from quantum chaos theory. Thus, ETH provides a physical basis for the technical condition needed by QET. This results in a unification of two formerly disparate schools of thought on the foundations of statistical mechanics. Quantum Quenches: As mentioned in the introduction, ETH has been shown to be satisfied in a variety of nonintegrable quantum systems. It has been found to breakdown only as one approaches integrable points  [6] [7] [8] , or in special regimes that are dominated by finite size effects, e.g., close to the atomic limit  [14, 15] . Thermalization itself has been shown to be robust in nonintegrable systems after a (sudden) quench, once again, failing to occur close to integrable points  [6, 16, 17]  or the atomic limit  [15, 18] , and in localized disordered systems  [19] . Here, by (sudden) quench, we mean that the system is prepared in an eigenstate of some initial Hamiltonian (not necessarily the ground state) and then at τ = 0 the Hamiltonian is changed. We now consider systems that do not satisfy ETH; in particular, we consider systems for which A αα varies significantly [that is, by an amount that is O(N 0 )] with α. It is easy to construct such systems; for example, any set of noninteracting degrees of freedom, with Â corresponding to any one-or few-body observable, is in this class. Interacting systems that are integrable (with as many conserved charges as degrees of freedom) are in this class  [20] . Equation (3) still applies to such systems; but now whether or not A is close to the thermal average of Â depends strongly on the initial state, which is specified by the C α coefficients. If the values of the coefficients |C α | 2 in Eq. (  3 ) provide an unbiased sampling of the matrix elements A αα , then we can expect A to be algebraically close to the microcanonical average of Â over the energy window specified by the ∆E of the initial state. The above scenario, however, does not occur in quenches between integrable systems, i.e., when the initial state is an eigenstate of an integrable system, and the time evolution is studied after changing some parameters in the Hamiltonian while keeping the system integrable. Studies of several models have shown that A remains different from the thermal expectation as one approaches the thermodynamic limit  [9, [21] [22] [23] [24] [25] [26] [27] [28] [29] [30] [31] [32] [33] [34] . Even some special initial states that were seen to lead to A similar to the ones predicted in thermal equilibrium  [9, 21, 28] , have been recently shown not to result in the thermalization Â in the thermodynamic limit  [32, 34] . Here we identify a class of initial states that leads to thermal behavior after a quench to an integrable point. The initial states we consider are eigenstates of an initial Hamiltonian ĤI that is nonintegrable. This Hamiltonian is constructed by breaking the integrability of the final Hamiltonian ĤF ; i.e., we set ĤI = ĤF + "integrability breaking terms". The idea here is that the integrability breaking terms in the initial Hamiltonian generate eigenstates that are unbiased combinations of eigenstates of the integrable (final) Hamiltonian. This is what leads to chaotic behavior as one departs from an integrable point  [7] , and ultimately allows ETH to be valid in nonintegrable systems. Hence, such initial states enable the desired unbiased sampling that is not provided by eigenstates of integrable systems. In order to show that this is indeed the case, we have studied one-dimensional lattice systems of hard-core bosons and spinless fermions with the Hamiltonian H = L j=1 -t ĉ † j ĉj+1 + H.c. -t ′ ĉ † j ĉj+2 + H.c. + V nj -1 2 nj+1 -1 2 + V ′ nj -1 2 nj+2 -1 2 , (4) where ĉ † j (ĉ j ) stands for the creation (annihilation) operator for hard-core bosons and fermions, nj = ĉ † j ĉj is the site occupation operator, L is the number of lattice sites, and t (t ′ ) and V (V ′ ) are the nearest (next-nearest) neighbor hopping and interaction, respectively. The t ′ , V ′ terms are the ones that make this Hamiltonian nonintegrable. We consider periodic boundary conditions, and the full diagonalization of the Hamiltonian is done using its translational symmetry. The filling is always taken to be N = L/3. Our quench protocol is then as follows, we generate an initial state |ψ I that is an eigenstate of Eq. (  4 ) with t = V = 1 (this sets our energy scale), t ′ = V ′ = 0, and which lies within the sector of zero total momentum. The final Hamiltonian, after the quench, still has t = V = 1, but we set t ′ = V ′ = 0. This Hamiltonian is integrable. We then study the relaxation dynamics of various observables, as well as their description after relaxation, for many different initial states. These initial states are eigenstates of Hamiltonians with different values of t ′ , V ′ , and are selected so that the system can have different final effective temperatures. The effective temperature T is calculated using the standard procedure for the canonical ensemble, i.e., such that We have studied four observables, the kinetic energy K, the interaction energy Û , the momentum distribution function nk (which is the Fourier transform of the one-particle correlations ρij = ĉ † i ĉj ), and the structure factor Nk (which the Fourier transform of the density-density correlations Nij = ni nj ). K and Û are local observables while nk and Nk are nonlocal, and K and nk are single-body observables while Û and Nk are two-body observables. In all cases studied, we found a similar qualitative behavior in those four quantities. Hence, we will only report results for nk , which is the one with the closest connection to ultracold gases experiments  [35] [36] [37] [38] . E = Z - We are first interested in understanding how is it that, given our quench protocol, observables relax (if they do) to the longtime average in Eq.  (3) . For nk , this can be conveniently quantified by calculating the normalized integrated difference δn k (τ ) = k | nk (τ ) -n k | k n k . ( 5 ) Results for δn k (τ ) are shown in Fig.  1  for bosons (left column) and fermions (right column) and for two different system sizes. For very small quenches [Fig.  1  Relative difference between n k as predicted by the microcanonical ensemble and the long-time average, as a function of t ′ , V ′ in the initial Hamiltonian. Results are reported for hard-core bosons (a) and spinless fermions (b), for lattices with 24 sites (main panels) and 21 sites (insets). In all systems, we considered five different initial states that resulted in five effective temperatures after the quench (T = 2, 3, 5, 7, and 10 in the plots). n k is close to the long-time average, and large oscillations (relative to the time average) can be seen for both bosons and fermions. By increasing the amplitude of the quench, the initial momentum distribution becomes increasingly different from the long-time average, and the time fluctuations decrease. This is because more eigenstates of the final Hamiltonian are involved in the dynamics and dephasing becomes more efficient. It is interesting to note the strikingly large finite size effects seen for the spinless fermions [Fig.  1 (e)-(g)], where the dynamics changes (improves) dramatically by increasing the system size from L = 21 to L = 24  [6, 7] . Overall, one can conclude from those results that, as the system size increases, n k relaxes to the long-time average rather quickly (τ ∼ /t), and the time fluctuations around that average become very small. Similar results were found for other observables and effective temperatures. We then are left to check how accurate statistical ensembles are when predicting n k . For our small finite systems, we use the microcanonical ensemble, and calculate the following normalized integrated difference to quantify its accuracy ∆n k = k | nk mc -n k | k n k . ( 6 ) The width ∆E of the energy window in the microcanonical ensemble is taken such that the results are robust to small changes of ∆E (in our systems ∆E ∼0.1-0.3). L = 21 (insets). In that figure, it is apparent that ∆n k is nonzero, and large, even in the absence of a quench (when t ′ = V ′ = 0 in the initial and final Hamiltonian). This reflects the failure of ETH due to integrability. However, as the value of t ′ , V ′ is increased, ∆n k is seen to decrease in all cases. This can be seen for bosons and fermions at all effective temperatures and in all system sizes. For all observables and effective temperatures that we have studied, we have found that ∆n k decreases with increasing system size. This, together with the understanding of the role of the integrability breaking terms in the initial Hamiltonian, supports our expectation that initial states that satisfy ETH (eigenstates of a nonintegrable Hamiltonian) will lead to thermalization in integrable systems, despite the fact that the latter do not satisfy ETH. In Fig.  2 , one can also see that, in many instances, ∆n k for a fixed system size reaches a minimum value and then increases as t ′ and V ′ are increased. This occur because, for large values of t ′ , V ′ , the initial state starts having large overlaps with eigenstates outside the microcanonical energy window. Hence, even though the initial state is sampling more eigenstates of the final Hamiltonian, the energy density becomes broad and the microcanonical ensemble once again becomes a bad approximation for the long-time average. The fact that more eigenstates of the final Hamiltonian are part of the initial state can be quantified by means of the inverse participation ratio (IPR) IPR = 1/ α |C α | 4 . This quantity has been shown to increase in eigenstates of nonintegrable manybody Hamiltonians as one departs from an integrable point  [7] . On the other hand, the fact that the weight of the initial state within the microcanonical window decreases if the value of t ′ , V ′ becomes too large can be quantified calculat- ing W = α ′ |C α ′ | 2 , where only eigenstates α ′ inside the microcanonical window are added. Then, one can compute a "normalized IPR", which is the product of the IPR and W . For finite systems, this quantity can tell us how effective t ′ , V ′ are in sampling states within the microcanonical window. Results for this quantity are depicted in Fig.  3 , for the same quenches depicted in Fig.  2 . Figure  3  shows that, in the region where ∆n k exhibits a sharp decrease in Fig.  2 , the normalized IPR increases. In addition, where ∆n k saturates or increases in Fig.  2 , the normalized IPR saturates or decreases in Fig.  3 . This allows one to understand the overall behavior of ∆n k in Fig.  2 . However, we should stress that the fact that t ′ , V ′ (or whatever other term is used to break integrability) cannot be made too large is only a concern for finite systems. As long as these terms are kept O(N 0 ) and the interactions have finite range, the energy width of any initial state after the quench will vanish in the thermodynamic limit  [5] , and the initial state will only sample states within the microcanonical window.

Conclusions:
In this paper we have further probed the role of the eigenstate thermalization hypothesis (ETH) as the key dynamical feature of systems that come to thermal equilibrium. We have shown that von Neumann's quantum ergodic theorem (QET) relies on a technical assumption that is in fact essentially equivalent to ETH. We have also examined whether thermal behavior can emerge in systems that do not obey ETH when the initial state is produced by a quench. We have found that this is possible, but only for a class of eigenstates that obeyed ETH before the quench. These results further support the fundamental role of ETH in thermal behavior of quantum many-body systems.