{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GROBID PDF Extraction\n",
    "\n",
    "PDF scientific paper text extraction using GROBID: \n",
    "- Github: https://github.com/kermitt2/grobid\n",
    "- Documentation: https://grobid.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used command for full GROBID model in docker:\n",
    "\n",
    "`docker run --rm --init --ulimit core=0 -p 8070:8070 grobid/grobid:0.8.2`\n",
    "\n",
    "(Converting all PDFs from this dataset took around 20 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_xml(input_pdf_path, output_xml_path):\n",
    "    if os.path.exists(output_xml_path):\n",
    "        print(f\"Already exists: {output_xml_path}\")\n",
    "        return\n",
    "    \n",
    "    url = \"http://localhost:8070/api/processFulltextDocument\"\n",
    "    with open(input_pdf_path, 'rb') as pdf_file:\n",
    "        files = {'input': pdf_file}\n",
    "        response = requests.post(url, files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            with open(output_xml_path, 'wb') as xml_file:\n",
    "                xml_file.write(response.content)\n",
    "            print(f\"Successfully converted: {output_xml_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to convert {input_pdf_path}. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "pdf_name = \"r001_A Fault Analysis Method for Three-Phase Induction Motors Based on Spiking Neural P Systems\"\n",
    "input_pdf_path = f\"../data/papers/{pdf_name}.pdf\"\n",
    "output_xml_path = f\"../data/extractions/full_model/{pdf_name}.xml\"\n",
    "convert_pdf_to_xml(input_pdf_path, output_xml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the PDF files\n",
    "pdf_directory = \"../data/papers\"\n",
    "\n",
    "# Iterate through all the files in the directory\n",
    "for filename in os.listdir(pdf_directory):\n",
    "    if filename.endswith(\".pdf\") and filename[0] == \"r\":\n",
    "        pdf_name = filename[:-4]  # Remove the .pdf extension\n",
    "        input_pdf_path = os.path.join(pdf_directory, filename)\n",
    "        output_xml_path = f\"../data/extractions/full_model/{pdf_name}.xml\"\n",
    "        convert_pdf_to_xml(input_pdf_path, output_xml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Body Text Extraction (PBTE)\n",
    "The following code is for extracting the relevant scientific text from the \"body\" tag of the TEI document in order to remove unwanted additional meta-information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_well_formatted(file_path):\n",
    "    try:\n",
    "        tree = etree.parse(file_path)\n",
    "        # print(\"XML is well-formed\")\n",
    "        return True\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(\"XML Syntax Error:\", e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_body(element):\n",
    "    if element.tag.endswith('body'):\n",
    "        return element\n",
    "\n",
    "    for child in element:\n",
    "        body = get_body(child)\n",
    "        if body != None:\n",
    "            return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_text_from_divs(body):\n",
    "    collected_text = []\n",
    "    for div in body.findall(\".//{*}div\"):\n",
    "        # Check if the div is not within a figure or other excluded tags\n",
    "        if not any(parent.tag.endswith(\"figure\") for parent in div.iterancestors()):\n",
    "            itered_texts = list(div.itertext())\n",
    "            collected_text.append(f\"{itered_texts[0]}\\n{' '.join(itered_texts[1:])}\")\n",
    "    return \"\\n\\n\".join(collected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paper_text(file_path):\n",
    "    print(file_path)\n",
    "    tree = etree.parse(file_path)\n",
    "    body = get_body(tree.getroot())\n",
    "    text = collect_text_from_divs(body)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xml_to_text(input_xml_path, output_text_path):\n",
    "    if os.path.exists(output_text_path):\n",
    "        print(f\"Already exists: {output_text_path}\")\n",
    "        return\n",
    "    \n",
    "    if not is_well_formatted(input_xml_path):\n",
    "        return\n",
    "    \n",
    "    text = extract_paper_text(input_xml_path)\n",
    "    with open(output_text_path, 'w') as text_file:\n",
    "        text_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the XML files\n",
    "xml_directory = \"../data/extractions\"\n",
    "\n",
    "# Iterate through all the files in the directory\n",
    "for filename in os.listdir(xml_directory):\n",
    "    if filename.endswith(\".xml\") and filename[0] == \"r\":\n",
    "        xml_name = filename[:-4]  # Remove the .xml extension\n",
    "        print(xml_name)\n",
    "        input_xml_path = f\"{xml_directory}/{xml_name}.xml\"\n",
    "        output_text_path = f\"../data/extractions/only_text/{xml_name}.txt\"\n",
    "        convert_xml_to_text(input_xml_path, output_text_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
