{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt-3.5-turbo-0125\", \"gpt-4-0125-preview\", \"gpt-4o-2024-05-13\", \"llama3.1:70b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_df(model_type, embedding, no_prev_chunking, gpt_model, batched):\n",
    "    path = f\"../data/dfs/{embedding}{'_no_prev_chunking' if no_prev_chunking else ''}/{model_type}/ReferenceErrorDetection_data_with_prompt_results{'_batched' if batched else ''}{'_'+gpt_model if gpt_model != models[0] else ''}.pkl\"\n",
    "    df = pd.read_pickle(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_json_colons(json_text):\n",
    "    if json_text and '{' in json_text and '}' in json_text:\n",
    "        json_text = json_text[json_text.find('{'):json_text.rfind('}') + 1]\n",
    "    return json_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Add extra columns for the model classification label and explanation by extracting the information from the JSON\n",
    "# If the JSON is misformed due to leading ```json and trailing ``` then remove them\n",
    "# Make sure that correct label and model label are both lower case and do not end with d (unsubstaniate instead of unsubstantiated)\n",
    "def reshape_model_classification(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Reference Article Downloaded'] == 'Yes':\n",
    "            try:\n",
    "                row['Model Classification'] = remove_json_colons(row['Model Classification'])\n",
    "                model_classification = json.loads(row['Model Classification'])\n",
    "                label = model_classification['label'].lower()\n",
    "                df.at[row.name, 'Model Classification Label'] = label if not label.endswith('d') else label[:-1]\n",
    "                df.at[row.name, 'Model Classification Explanation'] = model_classification['explanation']\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Row {index} Model Classification could not be decoded: {e}\")\n",
    "                print(row['Model Classification'])\n",
    "                df.at[row.name, 'Model Classification Label'] = None\n",
    "                df.at[row.name, 'Model Classification Explanation'] = None\n",
    "        else:\n",
    "            df.at[row.name, 'Model Classification Label'] = None\n",
    "            df.at[row.name, 'Model Classification Explanation'] = None\n",
    "        df.at[row.name, 'Label'] = df.at[row.name, 'Label'].lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_predictions_all_labels(df, include_not_originally_downloaded=True):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    false_predictions = 0\n",
    "\n",
    "    # What was the target label and what did the model predict (first hierarchy is target label, second is model label)\n",
    "    type_predictions = {\n",
    "        'unsubstantiate': {\n",
    "            'total': 0,\n",
    "            'unsubstantiate': 0,\n",
    "            'partially substantiate': 0,\n",
    "            'fully substantiate': 0,\n",
    "            'invalid label': 0,\n",
    "        },\n",
    "        'partially substantiate': {\n",
    "            'total': 0,\n",
    "            'unsubstantiate': 0,\n",
    "            'partially substantiate': 0,\n",
    "            'fully substantiate': 0,\n",
    "            'invalid label': 0,\n",
    "        },\n",
    "        'fully substantiate': {\n",
    "            'total': 0,\n",
    "            'unsubstantiate': 0,\n",
    "            'partially substantiate': 0,\n",
    "            'fully substantiate': 0,\n",
    "            'invalid label': 0,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Reference Article Downloaded'] == 'Yes':\n",
    "            if include_not_originally_downloaded or row['Reference Article PDF Available'] == 'Yes':\n",
    "                total += 1\n",
    "                target_label = row['Label']\n",
    "                type_predictions[target_label]['total'] += 1\n",
    "                model_label = row['Model Classification Label']\n",
    "\n",
    "                if model_label not in ['unsubstantiate', 'partially substantiate', 'fully substantiate']:\n",
    "                    false_predictions += 1\n",
    "                    type_predictions[target_label]['invalid label'] += 1\n",
    "                    print(f\"Row {index} Model Classification Label is not a valid label: {model_label}\")\n",
    "                    continue\n",
    "\n",
    "                type_predictions[target_label][model_label] += 1\n",
    "\n",
    "                if target_label == model_label:\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    false_predictions += 1\n",
    "    \n",
    "    evaluation_results = {\n",
    "        'accuracy': round(correct / total, 3),\n",
    "        'total': total,\n",
    "        'correct': correct,\n",
    "        'false_predictions': false_predictions,\n",
    "        'type_predictions': type_predictions\n",
    "    }\n",
    "\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_substantiate_label(label):\n",
    "    if label in ['partially substantiate', 'fully substantiate']:\n",
    "        label = 'substantiate'\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_predictions_two_labels(df, include_not_originally_downloaded=True):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    false_predictions = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Reference Article Downloaded'] == 'Yes':\n",
    "            if include_not_originally_downloaded or row['Reference Article PDF Available'] == 'Yes':\n",
    "                total += 1\n",
    "                target_label = replace_substantiate_label(row['Label'])\n",
    "                model_label = replace_substantiate_label(row['Model Classification Label'])\n",
    "\n",
    "                if target_label == model_label:\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    false_predictions += 1\n",
    "                    if model_label not in ['unsubstantiate', 'substantiate']:\n",
    "                        print(f\"Row {index} Model Classification Label is not a valid label: {model_label}\")\n",
    "                    elif target_label == 'unsubstantiate' and model_label == 'substantiate':\n",
    "                        false_positives += 1\n",
    "                    elif target_label == 'substantiate' and model_label == 'unsubstantiate':\n",
    "                        false_negatives += 1\n",
    "    \n",
    "    evaluation_results = {\n",
    "        'accuracy': round(correct / total, 3),\n",
    "        'total': total,\n",
    "        'correct': correct,\n",
    "        'false_predictions': false_predictions,\n",
    "        'false_positives': false_positives,\n",
    "        'false_negatives': false_negatives\n",
    "    }\n",
    "\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Results: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {\n",
    "    \"te3s\": {},\n",
    "    \"te3s_no_prev_chunking\": {},\n",
    "    \"te3s_no_prev_chunking_batched\": {},\n",
    "    \"te3l\": {},\n",
    "    \"te3l_no_prev_chunking\": {},\n",
    "    \"te3l_no_prev_chunking_batched\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_results(model_type, embedding, no_prev_chunking, batched, gpt_model=models[0]):\n",
    "    global all_results\n",
    "\n",
    "    df = load_df(model_type, embedding, no_prev_chunking, gpt_model, batched)\n",
    "    df = reshape_model_classification(df)\n",
    "    \n",
    "    results_all_labels = eval_predictions_all_labels(df)\n",
    "    results_all_labels_exlude_not_available = eval_predictions_all_labels(df, False)\n",
    "    results_two_labels = eval_predictions_two_labels(df)\n",
    "    results_two_labels_exlude_not_available = eval_predictions_two_labels(df, False)\n",
    "\n",
    "    results = {\n",
    "        'all_labels': results_all_labels,\n",
    "        'all_labels_exclude_not_available': results_all_labels_exlude_not_available,\n",
    "        'two_labels': results_two_labels,\n",
    "        'two_labels_exclude_not_available': results_two_labels_exlude_not_available\n",
    "    }\n",
    "\n",
    "    embedding_string = embedding + ('_no_prev_chunking' if no_prev_chunking else '') + ('_batched' if batched else '')\n",
    "\n",
    "    if not isinstance(all_results[embedding_string].get(model_type), dict):\n",
    "        all_results[embedding_string][model_type] = {}\n",
    "    all_results[embedding_string][model_type][gpt_model] = results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small GROBID Model\n",
    "- PDF text extracted with smaller GROBID model \n",
    "- full text from TEI document directly fed into index generation \n",
    "- Model temperature set to 0 (for top 3 excerpts retrieval and for classification via model prompting)\n",
    "- Used embedding for index: text-embedding-3-small\n",
    "- Used model for prompting: gpt-3.5-turbo-0125\n",
    "\n",
    "#### Small Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"small_model\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = False\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full GROBID Model\n",
    "- PDF text extracted with full GROBID model\n",
    "- full text from TEI document directly fed into index generation \n",
    "- Model temperature set to 0 (for top 3 excerpts retrieval and for classification via model prompting)\n",
    "- Used embedding for index: text-embedding-3-small\n",
    "- Used model for prompting: gpt-3.5-turbo-0125\n",
    "\n",
    "#### Small Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = False\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Text Embedding - no previous chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = True\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Text Embedding - no previous chunking - batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = True\n",
    "batched = True\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = False\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Text Embedding - no previous chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPT 3 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = True\n",
    "batched = False\n",
    "model = models[0]\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = True\n",
    "batched = False\n",
    "model = models[1]\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPT 4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = True\n",
    "batched = False\n",
    "model = models[2]\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Llama 3.1 (70b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = True\n",
    "batched = False\n",
    "model = models[3]\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Text Embedding - no previous chunking - batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = True\n",
    "batched = True\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full GROBID Model + TEI document text refactoring\n",
    "- PDF text extracted with full GROBID model\n",
    "- Only text from body of papers (actual content) extracted from TEI documents\n",
    "- Model temperature set to 0 (for top 3 excerpts retrieval and for classification via model prompting)\n",
    "- Used embedding for index: text-embedding-3-small\n",
    "- Used model for prompting: gpt-3.5-turbo-0125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"full_model_texts\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = False\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Text Embedding - no previous chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model_texts\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = True\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Text Embedding - no previous chunking - batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model_texts\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = True\n",
    "batched = True\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"full_model_texts\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = False\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Text Embedding - no previous chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model_texts\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = True\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Text Embedding - no previous chunking - batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model_texts\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = True\n",
    "batched = True\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/all_results.json\", \"w\") as json_file:\n",
    "    json.dump(all_results, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce Table from Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_for_table = all_results['te3l_no_prev_chunking']['full_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-3.5-turbo-0125': {'all_labels': {'accuracy': 0.567,\n",
       "   'total': 247,\n",
       "   'correct': 140,\n",
       "   'false_predictions': 107,\n",
       "   'type_predictions': {'unsubstantiate': {'total': 109,\n",
       "     'unsubstantiate': 78,\n",
       "     'partially substantiate': 16,\n",
       "     'fully substantiate': 14,\n",
       "     'invalid label': 1},\n",
       "    'partially substantiate': {'total': 14,\n",
       "     'unsubstantiate': 2,\n",
       "     'partially substantiate': 7,\n",
       "     'fully substantiate': 5,\n",
       "     'invalid label': 0},\n",
       "    'fully substantiate': {'total': 124,\n",
       "     'unsubstantiate': 11,\n",
       "     'partially substantiate': 58,\n",
       "     'fully substantiate': 55,\n",
       "     'invalid label': 0}}},\n",
       "  'all_labels_exclude_not_available': {'accuracy': 0.57,\n",
       "   'total': 244,\n",
       "   'correct': 139,\n",
       "   'false_predictions': 105,\n",
       "   'type_predictions': {'unsubstantiate': {'total': 108,\n",
       "     'unsubstantiate': 78,\n",
       "     'partially substantiate': 15,\n",
       "     'fully substantiate': 14,\n",
       "     'invalid label': 1},\n",
       "    'partially substantiate': {'total': 14,\n",
       "     'unsubstantiate': 2,\n",
       "     'partially substantiate': 7,\n",
       "     'fully substantiate': 5,\n",
       "     'invalid label': 0},\n",
       "    'fully substantiate': {'total': 122,\n",
       "     'unsubstantiate': 10,\n",
       "     'partially substantiate': 58,\n",
       "     'fully substantiate': 54,\n",
       "     'invalid label': 0}}},\n",
       "  'two_labels': {'accuracy': 0.822,\n",
       "   'total': 247,\n",
       "   'correct': 203,\n",
       "   'false_predictions': 44,\n",
       "   'false_positives': 30,\n",
       "   'false_negatives': 13},\n",
       "  'two_labels_exclude_not_available': {'accuracy': 0.828,\n",
       "   'total': 244,\n",
       "   'correct': 202,\n",
       "   'false_predictions': 42,\n",
       "   'false_positives': 29,\n",
       "   'false_negatives': 12}},\n",
       " 'gpt-4-0125-preview': {'all_labels': {'accuracy': 0.7,\n",
       "   'total': 247,\n",
       "   'correct': 173,\n",
       "   'false_predictions': 74,\n",
       "   'type_predictions': {'unsubstantiate': {'total': 109,\n",
       "     'unsubstantiate': 93,\n",
       "     'partially substantiate': 4,\n",
       "     'fully substantiate': 12,\n",
       "     'invalid label': 0},\n",
       "    'partially substantiate': {'total': 14,\n",
       "     'unsubstantiate': 5,\n",
       "     'partially substantiate': 2,\n",
       "     'fully substantiate': 7,\n",
       "     'invalid label': 0},\n",
       "    'fully substantiate': {'total': 124,\n",
       "     'unsubstantiate': 19,\n",
       "     'partially substantiate': 27,\n",
       "     'fully substantiate': 78,\n",
       "     'invalid label': 0}}},\n",
       "  'all_labels_exclude_not_available': {'accuracy': 0.701,\n",
       "   'total': 244,\n",
       "   'correct': 171,\n",
       "   'false_predictions': 73,\n",
       "   'type_predictions': {'unsubstantiate': {'total': 108,\n",
       "     'unsubstantiate': 92,\n",
       "     'partially substantiate': 4,\n",
       "     'fully substantiate': 12,\n",
       "     'invalid label': 0},\n",
       "    'partially substantiate': {'total': 14,\n",
       "     'unsubstantiate': 5,\n",
       "     'partially substantiate': 2,\n",
       "     'fully substantiate': 7,\n",
       "     'invalid label': 0},\n",
       "    'fully substantiate': {'total': 122,\n",
       "     'unsubstantiate': 18,\n",
       "     'partially substantiate': 27,\n",
       "     'fully substantiate': 77,\n",
       "     'invalid label': 0}}},\n",
       "  'two_labels': {'accuracy': 0.838,\n",
       "   'total': 247,\n",
       "   'correct': 207,\n",
       "   'false_predictions': 40,\n",
       "   'false_positives': 16,\n",
       "   'false_negatives': 24},\n",
       "  'two_labels_exclude_not_available': {'accuracy': 0.84,\n",
       "   'total': 244,\n",
       "   'correct': 205,\n",
       "   'false_predictions': 39,\n",
       "   'false_positives': 16,\n",
       "   'false_negatives': 23}},\n",
       " 'gpt-4o-2024-05-13': {'all_labels': {'accuracy': 0.587,\n",
       "   'total': 247,\n",
       "   'correct': 145,\n",
       "   'false_predictions': 102,\n",
       "   'type_predictions': {'unsubstantiate': {'total': 109,\n",
       "     'unsubstantiate': 92,\n",
       "     'partially substantiate': 11,\n",
       "     'fully substantiate': 6,\n",
       "     'invalid label': 0},\n",
       "    'partially substantiate': {'total': 14,\n",
       "     'unsubstantiate': 3,\n",
       "     'partially substantiate': 8,\n",
       "     'fully substantiate': 3,\n",
       "     'invalid label': 0},\n",
       "    'fully substantiate': {'total': 124,\n",
       "     'unsubstantiate': 23,\n",
       "     'partially substantiate': 56,\n",
       "     'fully substantiate': 45,\n",
       "     'invalid label': 0}}},\n",
       "  'all_labels_exclude_not_available': {'accuracy': 0.586,\n",
       "   'total': 244,\n",
       "   'correct': 143,\n",
       "   'false_predictions': 101,\n",
       "   'type_predictions': {'unsubstantiate': {'total': 108,\n",
       "     'unsubstantiate': 91,\n",
       "     'partially substantiate': 11,\n",
       "     'fully substantiate': 6,\n",
       "     'invalid label': 0},\n",
       "    'partially substantiate': {'total': 14,\n",
       "     'unsubstantiate': 3,\n",
       "     'partially substantiate': 8,\n",
       "     'fully substantiate': 3,\n",
       "     'invalid label': 0},\n",
       "    'fully substantiate': {'total': 122,\n",
       "     'unsubstantiate': 22,\n",
       "     'partially substantiate': 56,\n",
       "     'fully substantiate': 44,\n",
       "     'invalid label': 0}}},\n",
       "  'two_labels': {'accuracy': 0.826,\n",
       "   'total': 247,\n",
       "   'correct': 204,\n",
       "   'false_predictions': 43,\n",
       "   'false_positives': 17,\n",
       "   'false_negatives': 26},\n",
       "  'two_labels_exclude_not_available': {'accuracy': 0.828,\n",
       "   'total': 244,\n",
       "   'correct': 202,\n",
       "   'false_predictions': 42,\n",
       "   'false_positives': 17,\n",
       "   'false_negatives': 25}},\n",
       " 'llama3.1:70b': {'all_labels': {'accuracy': 0.559,\n",
       "   'total': 247,\n",
       "   'correct': 138,\n",
       "   'false_predictions': 109,\n",
       "   'type_predictions': {'unsubstantiate': {'total': 109,\n",
       "     'unsubstantiate': 95,\n",
       "     'partially substantiate': 10,\n",
       "     'fully substantiate': 4,\n",
       "     'invalid label': 0},\n",
       "    'partially substantiate': {'total': 14,\n",
       "     'unsubstantiate': 4,\n",
       "     'partially substantiate': 9,\n",
       "     'fully substantiate': 1,\n",
       "     'invalid label': 0},\n",
       "    'fully substantiate': {'total': 124,\n",
       "     'unsubstantiate': 33,\n",
       "     'partially substantiate': 57,\n",
       "     'fully substantiate': 34,\n",
       "     'invalid label': 0}}},\n",
       "  'all_labels_exclude_not_available': {'accuracy': 0.557,\n",
       "   'total': 244,\n",
       "   'correct': 136,\n",
       "   'false_predictions': 108,\n",
       "   'type_predictions': {'unsubstantiate': {'total': 108,\n",
       "     'unsubstantiate': 94,\n",
       "     'partially substantiate': 10,\n",
       "     'fully substantiate': 4,\n",
       "     'invalid label': 0},\n",
       "    'partially substantiate': {'total': 14,\n",
       "     'unsubstantiate': 4,\n",
       "     'partially substantiate': 9,\n",
       "     'fully substantiate': 1,\n",
       "     'invalid label': 0},\n",
       "    'fully substantiate': {'total': 122,\n",
       "     'unsubstantiate': 32,\n",
       "     'partially substantiate': 57,\n",
       "     'fully substantiate': 33,\n",
       "     'invalid label': 0}}},\n",
       "  'two_labels': {'accuracy': 0.794,\n",
       "   'total': 247,\n",
       "   'correct': 196,\n",
       "   'false_predictions': 51,\n",
       "   'false_positives': 14,\n",
       "   'false_negatives': 37},\n",
       "  'two_labels_exclude_not_available': {'accuracy': 0.795,\n",
       "   'total': 244,\n",
       "   'correct': 194,\n",
       "   'false_predictions': 50,\n",
       "   'false_positives': 14,\n",
       "   'false_negatives': 36}}}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_for_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_label_accuracies(results, exclude_not_available=False):\n",
    "    # Initialize dictionary\n",
    "    label_accuracies = {}\n",
    "    for model in results:\n",
    "        label_accuracies[model] = {\n",
    "            'unsubstantiate': None,\n",
    "            'partially substantiate': None,\n",
    "            'fully substantiate': None,\n",
    "            'overall': None,\n",
    "        }\n",
    "    \n",
    "    for model, model_results in results.items():\n",
    "        category_name = 'all_labels' + ('_exclude_not_available' if exclude_not_available else '')\n",
    "        type_predictions = model_results[category_name]['type_predictions']\n",
    "        for label in type_predictions:\n",
    "            label_accuracies[model][label] = round(type_predictions[label][label] / type_predictions[label]['total'], 3)\n",
    "        label_accuracies[model]['overall'] = round(model_results[category_name]['accuracy'], 3)\n",
    "    \n",
    "    return label_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def print_accuracies(label_accuracies):\n",
    "    # Prepare data for the table\n",
    "    table_data = [\n",
    "        [model, \n",
    "        f\"{accuracies['unsubstantiate'] * 100:.1f}\", \n",
    "        f\"{accuracies['partially substantiate'] * 100:.1f}\", \n",
    "        f\"{accuracies['fully substantiate'] * 100:.1f}\", \n",
    "        f\"{accuracies['overall'] * 100:.1f}\"]\n",
    "        for model, accuracies in label_accuracies.items()\n",
    "    ]\n",
    "\n",
    "    # Define headers\n",
    "    headers = ['Model', 'Un', 'Partially', 'Fully', 'Overall']\n",
    "\n",
    "    # Display the table\n",
    "    print(tabulate(table_data, headers=headers, tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Accuracies - Include All Downloaded\n",
      "+--------------------+------+-----------+-------+---------+\n",
      "|       Model        |  Un  | Partially | Fully | Overall |\n",
      "+--------------------+------+-----------+-------+---------+\n",
      "| gpt-3.5-turbo-0125 | 71.6 |   50.0    | 44.4  |  56.7   |\n",
      "| gpt-4-0125-preview | 85.3 |   14.3    | 62.9  |  70.0   |\n",
      "| gpt-4o-2024-05-13  | 84.4 |   57.1    | 36.3  |  58.7   |\n",
      "|    llama3.1:70b    | 87.2 |   64.3    | 27.4  |  55.9   |\n",
      "+--------------------+------+-----------+-------+---------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Label Accuracies - Include All Downloaded\")\n",
    "print_accuracies(calc_label_accuracies(results_for_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Accuracies - Exclude Not Available in Paper\n",
      "+--------------------+------+-----------+-------+---------+\n",
      "|       Model        |  Un  | Partially | Fully | Overall |\n",
      "+--------------------+------+-----------+-------+---------+\n",
      "| gpt-3.5-turbo-0125 | 72.2 |   50.0    | 44.3  |  57.0   |\n",
      "| gpt-4-0125-preview | 85.2 |   14.3    | 63.1  |  70.1   |\n",
      "| gpt-4o-2024-05-13  | 84.3 |   57.1    | 36.1  |  58.6   |\n",
      "|    llama3.1:70b    | 87.0 |   64.3    | 27.0  |  55.7   |\n",
      "+--------------------+------+-----------+-------+---------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Label Accuracies - Exclude Not Available in Paper\")\n",
    "print_accuracies(calc_label_accuracies(results_for_table, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to paper results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-3.5-turbo-0125': {'unsubstantiate': 0.716,\n",
       "  'partially substantiate': 0.5,\n",
       "  'fully substantiate': 0.444,\n",
       "  'overall': 0.567},\n",
       " 'gpt-4-0125-preview': {'unsubstantiate': 0.853,\n",
       "  'partially substantiate': 0.143,\n",
       "  'fully substantiate': 0.629,\n",
       "  'overall': 0.7},\n",
       " 'gpt-4o-2024-05-13': {'unsubstantiate': 0.844,\n",
       "  'partially substantiate': 0.571,\n",
       "  'fully substantiate': 0.363,\n",
       "  'overall': 0.587},\n",
       " 'llama3.1:70b': {'unsubstantiate': 0.872,\n",
       "  'partially substantiate': 0.643,\n",
       "  'fully substantiate': 0.274,\n",
       "  'overall': 0.559}}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_label_accuracies(results_for_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_results = {\n",
    "    'gpt-3.5-turbo-0125': {\n",
    "        'unsubstantiate': 0.795,\n",
    "        'partially substantiate': 0.571,\n",
    "        'fully substantiate': 0.306,\n",
    "        'overall': 0.540,\n",
    "    },\n",
    "    'gpt-4-0125-preview': {\n",
    "        'unsubstantiate': 0.839,\n",
    "        'partially substantiate': 0.214,\n",
    "        'fully substantiate': 0.629,\n",
    "        'overall': 0.700,\n",
    "    },\n",
    "    'gpt-4o-2024-05-13': {\n",
    "        'unsubstantiate': 0.866,\n",
    "        'partially substantiate': 0.500,\n",
    "        'fully substantiate': 0.347,\n",
    "        'overall': 0.588,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_difference_between_results(calculated_results, paper_results):\n",
    "    differences = {}\n",
    "    for model, results in paper_results.items():\n",
    "        if model in calculated_results:\n",
    "            differences[model] = {\n",
    "                key: round(1 - (1 / value * calculated_results[model][key]), 3)\n",
    "                for key, value in results.items()\n",
    "            }\n",
    "    return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-3.5-turbo-0125': {'unsubstantiate': 0.099,\n",
       "  'partially substantiate': 0.124,\n",
       "  'fully substantiate': -0.451,\n",
       "  'overall': -0.05},\n",
       " 'gpt-4-0125-preview': {'unsubstantiate': -0.017,\n",
       "  'partially substantiate': 0.332,\n",
       "  'fully substantiate': 0.0,\n",
       "  'overall': 0.0},\n",
       " 'gpt-4o-2024-05-13': {'unsubstantiate': 0.025,\n",
       "  'partially substantiate': -0.142,\n",
       "  'fully substantiate': -0.046,\n",
       "  'overall': 0.002}}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_difference_between_results(calc_label_accuracies(results_for_table), paper_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Accuracies - Exclude Not Available in Paper\n",
      "+--------------------+------+-----------+-------+---------+\n",
      "|       Model        |  Un  | Partially | Fully | Overall |\n",
      "+--------------------+------+-----------+-------+---------+\n",
      "| gpt-3.5-turbo-0125 | 72.2 |   50.0    | 44.3  |  57.0   |\n",
      "| gpt-4-0125-preview | 85.2 |   14.3    | 63.1  |  70.1   |\n",
      "| gpt-4o-2024-05-13  | 84.3 |   57.1    | 36.1  |  58.6   |\n",
      "|    llama3.1:70b    | 87.0 |   64.3    | 27.0  |  55.7   |\n",
      "+--------------------+------+-----------+-------+---------+\n",
      "\n",
      "Paper Results\n",
      "+--------------------+------+-----------+-------+---------+\n",
      "|       Model        |  Un  | Partially | Fully | Overall |\n",
      "+--------------------+------+-----------+-------+---------+\n",
      "| gpt-3.5-turbo-0125 | 79.5 |   57.1    | 30.6  |  54.0   |\n",
      "| gpt-4-0125-preview | 83.9 |   21.4    | 62.9  |  70.0   |\n",
      "| gpt-4o-2024-05-13  | 86.6 |   50.0    | 34.7  |  58.8   |\n",
      "+--------------------+------+-----------+-------+---------+\n",
      "\n",
      "Difference from paper to calculated results\n",
      "+--------------------+------+-----------+-------+---------+\n",
      "|       Model        |  Un  | Partially | Fully | Overall |\n",
      "+--------------------+------+-----------+-------+---------+\n",
      "| gpt-3.5-turbo-0125 | 9.2  |   12.4    | -44.8 |  -5.6   |\n",
      "| gpt-4-0125-preview | -1.5 |   33.2    | -0.3  |  -0.1   |\n",
      "| gpt-4o-2024-05-13  | 2.7  |   -14.2   | -4.0  |   0.3   |\n",
      "+--------------------+------+-----------+-------+---------+\n"
     ]
    }
   ],
   "source": [
    "label_accuracies = calc_label_accuracies(results_for_table, True)\n",
    "print(\"Label Accuracies - Exclude Not Available in Paper\")\n",
    "print_accuracies(label_accuracies)\n",
    "print(\"\")\n",
    "print(\"Paper Results\")\n",
    "print_accuracies(paper_results)\n",
    "print(\"\")\n",
    "print(\"Difference from paper to calculated results\")\n",
    "print_accuracies(calc_difference_between_results(label_accuracies, paper_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
