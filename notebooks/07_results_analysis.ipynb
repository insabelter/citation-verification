{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt-3.5-turbo-0125\", \"gpt-4-0125-preview\", \"gpt-4o-2024-05-13\", \"gpt-4-turbo-preview\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_df(model_type, embedding, no_prev_chunking, gpt_model, batched):\n",
    "    path = f\"../data/dfs/{embedding}{'_no_prev_chunking' if no_prev_chunking else ''}/{model_type}/ReferenceErrorDetection_data_with_prompt_results{'_batched' if batched else ''}{'_'+gpt_model if gpt_model != models[0] else ''}.pkl\"\n",
    "    df = pd.read_pickle(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_json_colons(json_text):\n",
    "    if json_text and json_text.startswith(\"```json\") and json_text.rstrip().endswith(\"```\"):\n",
    "        return json_text[7:-3]\n",
    "    return json_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Add extra columns for the model classification label and explanation by extracting the information from the JSON\n",
    "# If the JSON is misformed due to leading ```json and trailing ``` then remove them\n",
    "# Make sure that correct label and model label are both lower case and do not end with d (unsubstaniate instead of unsubstantiated)\n",
    "def reshape_model_classification(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Reference Article Downloaded'] == 'Yes':\n",
    "            try:\n",
    "                row['Model Classification'] = remove_json_colons(row['Model Classification'])\n",
    "                model_classification = json.loads(row['Model Classification'])\n",
    "                label = model_classification['label'].lower()\n",
    "                df.at[row.name, 'Model Classification Label'] = label if not label.endswith('d') else label[:-1]\n",
    "                df.at[row.name, 'Model Classification Explanation'] = model_classification['explanation']\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Row {index} Model Classification could not be decoded: {e}\")\n",
    "                print(row['Model Classification'])\n",
    "                df.at[row.name, 'Model Classification Label'] = None\n",
    "                df.at[row.name, 'Model Classification Explanation'] = None\n",
    "        else:\n",
    "            df.at[row.name, 'Model Classification Label'] = None\n",
    "            df.at[row.name, 'Model Classification Explanation'] = None\n",
    "        df.at[row.name, 'Label'] = df.at[row.name, 'Label'].lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_predictions_all_labels(df, include_not_originally_downloaded=True):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    false_predictions = 0\n",
    "\n",
    "    # What was the target label and what did the model predict (first hierarchy is target label, second is model label)\n",
    "    type_false_predictions = {\n",
    "        'unsubstantiate': {\n",
    "            'partially substantiate': 0,\n",
    "            'fully substantiate': 0\n",
    "        },\n",
    "        'partially substantiate': {\n",
    "            'unsubstantiate': 0,\n",
    "            'fully substantiate': 0\n",
    "        },\n",
    "        'fully substantiate': {\n",
    "            'unsubstantiate': 0,\n",
    "            'partially substantiate': 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Reference Article Downloaded'] == 'Yes':\n",
    "            if include_not_originally_downloaded or row['Reference Article PDF Available'] == 'Yes':\n",
    "                total += 1\n",
    "                target_label = row['Label']\n",
    "                model_label = row['Model Classification Label']\n",
    "\n",
    "                if target_label == model_label:\n",
    "                    correct += 1\n",
    "                elif model_label not in ['unsubstantiate', 'partially substantiate', 'fully substantiate']:\n",
    "                    false_predictions += 1\n",
    "                    print(f\"Row {index} Model Classification Label is not a valid label: {model_label}\")\n",
    "                    print(row['Model Classification'])\n",
    "                else:\n",
    "                    false_predictions += 1\n",
    "                    type_false_predictions[target_label][model_label] += 1\n",
    "    \n",
    "    evaluation_results = {\n",
    "        'accuracy': round(correct / total, 4),\n",
    "        'total': total,\n",
    "        'correct': correct,\n",
    "        'false_predictions': false_predictions,\n",
    "        'type_false_predictions': type_false_predictions\n",
    "    }\n",
    "\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_substantiate_label(label):\n",
    "    if label in ['partially substantiate', 'fully substantiate']:\n",
    "        label = 'substantiate'\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_predictions_two_labels(df, include_not_originally_downloaded=True):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    false_predictions = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Reference Article Downloaded'] == 'Yes':\n",
    "            if include_not_originally_downloaded or row['Reference Article PDF Available'] == 'Yes':\n",
    "                total += 1\n",
    "                target_label = replace_substantiate_label(row['Label'])\n",
    "                model_label = replace_substantiate_label(row['Model Classification Label'])\n",
    "\n",
    "                if target_label == model_label:\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    false_predictions += 1\n",
    "                    if model_label not in ['unsubstantiate', 'substantiate']:\n",
    "                        print(f\"Row {index} Model Classification Label is not a valid label: {model_label}\")\n",
    "                    elif target_label == 'unsubstantiate' and model_label == 'substantiate':\n",
    "                        false_positives += 1\n",
    "                    elif target_label == 'substantiate' and model_label == 'unsubstantiate':\n",
    "                        false_negatives += 1\n",
    "    \n",
    "    evaluation_results = {\n",
    "        'accuracy': round(correct / total, 4),\n",
    "        'total': total,\n",
    "        'correct': correct,\n",
    "        'false_predictions': false_predictions,\n",
    "        'false_positives': false_positives,\n",
    "        'false_negatives': false_negatives\n",
    "    }\n",
    "\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Results: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {\n",
    "    \"te3s\": {},\n",
    "    \"te3s_no_prev_chunking\": {},\n",
    "    \"te3s_no_prev_chunking_batched\": {},\n",
    "    \"te3l\": {},\n",
    "    \"te3l_no_prev_chunking\": {},\n",
    "    \"te3l_no_prev_chunking_batched\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_results(model_type, embedding, no_prev_chunking, batched, gpt_model=models[0]):\n",
    "    global all_results\n",
    "\n",
    "    df = load_df(model_type, embedding, no_prev_chunking, gpt_model, batched)\n",
    "    df = reshape_model_classification(df)\n",
    "    \n",
    "    results_all_labels = eval_predictions_all_labels(df)\n",
    "    results_all_labels_exlude_not_available = eval_predictions_all_labels(df, False)\n",
    "    results_two_labels = eval_predictions_two_labels(df)\n",
    "    results_two_labels_exlude_not_available = eval_predictions_two_labels(df, False)\n",
    "\n",
    "    results = {\n",
    "        'all_labels': results_all_labels,\n",
    "        'all_labels_exclude_not_available': results_all_labels_exlude_not_available,\n",
    "        'two_labels': results_two_labels,\n",
    "        'two_labels_exclude_not_available': results_two_labels_exlude_not_available\n",
    "    }\n",
    "\n",
    "    embedding_string = embedding + ('_no_prev_chunking' if no_prev_chunking else '') + ('_batched' if batched else '')\n",
    "\n",
    "    if not isinstance(all_results[embedding_string].get(model_type), dict):\n",
    "        all_results[embedding_string][model_type] = {}\n",
    "    all_results[embedding_string][model_type][gpt_model] = results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small GROBID Model\n",
    "- PDF text extracted with smaller GROBID model \n",
    "- full text from TEI document directly fed into index generation \n",
    "- Model temperature set to 0 (for top 3 excerpts retrieval and for classification via model prompting)\n",
    "- Used embedding for index: text-embedding-3-small\n",
    "- Used model for prompting: gpt-3.5-turbo-0125\n",
    "\n",
    "#### Small Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"small_model\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = False\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full GROBID Model\n",
    "- PDF text extracted with full GROBID model\n",
    "- full text from TEI document directly fed into index generation \n",
    "- Model temperature set to 0 (for top 3 excerpts retrieval and for classification via model prompting)\n",
    "- Used embedding for index: text-embedding-3-small\n",
    "- Used model for prompting: gpt-3.5-turbo-0125\n",
    "\n",
    "#### Small Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = False\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Text Embedding - no previous chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = True\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Text Embedding - no previous chunking - batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = True\n",
    "batched = True\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = False\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Text Embedding - no previous chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPT 3 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = True\n",
    "batched = False\n",
    "model = models[0]\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = True\n",
    "batched = False\n",
    "model = models[1]\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPT 4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = True\n",
    "batched = False\n",
    "model = models[2]\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Text Embedding - no previous chunking - batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = True\n",
    "batched = True\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full GROBID Model + TEI document text refactoring\n",
    "- PDF text extracted with full GROBID model\n",
    "- Only text from body of papers (actual content) extracted from TEI documents\n",
    "- Model temperature set to 0 (for top 3 excerpts retrieval and for classification via model prompting)\n",
    "- Used embedding for index: text-embedding-3-small\n",
    "- Used model for prompting: gpt-3.5-turbo-0125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"full_model_texts\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = False\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Text Embedding - no previous chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model_texts\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = True\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Text Embedding - no previous chunking - batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model_texts\"\n",
    "embedding = \"te3s\"\n",
    "no_prev_chunking = True\n",
    "batched = True\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"full_model_texts\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = False\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Text Embedding - no previous chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model_texts\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = True\n",
    "batched = False\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Text Embedding - no previous chunking - batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 Model Classification could not be decoded: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "{\n",
      "\n",
      "Row 22 Model Classification Label is not a valid label: None\n",
      "Row 22 Model Classification Label is not a valid label: None\n"
     ]
    }
   ],
   "source": [
    "model_type = \"full_model_texts\"\n",
    "embedding = \"te3l\"\n",
    "no_prev_chunking = True\n",
    "batched = True\n",
    "gather_results(model_type, embedding, no_prev_chunking, batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/all_results.json\", \"w\") as json_file:\n",
    "    json.dump(all_results, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
