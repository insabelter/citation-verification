{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting the models to classify the statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 3.5 and GPT 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "%run ./04_prompt_creation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/dfs/only_text_256_20/ReferenceErrorDetection_data_with_chunk_info.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunking = \"256_20\"\n",
    "only_text = True\n",
    "\n",
    "path = f\"../data/dfs/{'only_text_' if only_text else ''}{chunking}/ReferenceErrorDetection_data_with_chunk_info.pkl\"\n",
    "print(path)\n",
    "\n",
    "# read the dataframe from a pickle file\n",
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Citing Article ID</th>\n",
       "      <th>Citing Article DOI</th>\n",
       "      <th>Citing Article Title</th>\n",
       "      <th>Citing Article Retracted</th>\n",
       "      <th>Citing Article Downloaded</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Citation ID</th>\n",
       "      <th>Statement with Citation</th>\n",
       "      <th>Corrected Statement</th>\n",
       "      <th>...</th>\n",
       "      <th>Reference Article PDF Available</th>\n",
       "      <th>Reference Article Retracted</th>\n",
       "      <th>Reference Article Downloaded</th>\n",
       "      <th>Label</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>Error Type</th>\n",
       "      <th>Added</th>\n",
       "      <th>Previously Partially Substantiated</th>\n",
       "      <th>Top_3_Chunk_IDs</th>\n",
       "      <th>Top_3_Chunk_Texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c001</td>\n",
       "      <td>10.1016/j.est.2021.103553</td>\n",
       "      <td>Heating a residential building using the heat ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>cit001_1</td>\n",
       "      <td>Others have aimed to reduce irreversibility or...</td>\n",
       "      <td>Others have aimed to reduce irreversibility or...</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiated</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[15e4928e-d5b4-4358-a37a-0e2eef963320, 4472c31...</td>\n",
       "      <td>[68. (8 ) σ 1 σ 17 σ 18 σ 31 σ 30 σ 41 σ 46 σ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c001</td>\n",
       "      <td>10.1016/j.est.2021.103553</td>\n",
       "      <td>Heating a residential building using the heat ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>cit001_2</td>\n",
       "      <td>Some researchers have also studied various hea...</td>\n",
       "      <td>Some researchers have also studied various hea...</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiated</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1815ea07-43b1-4b3f-bbf0-35876f1f2e2f, cfeb9f2...</td>\n",
       "      <td>[The evaluations of nanofluid thermo-physical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c002</td>\n",
       "      <td>10.1155/2022/4601350</td>\n",
       "      <td>Oxidative Potential and Nanoantioxidant Activi...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>cit002_1</td>\n",
       "      <td>The relative content of total flavonoids in th...</td>\n",
       "      <td>The relative content of total flavonoids in th...</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiated</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3d0ce96f-8ffb-4347-b469-d35015b7ef3a, 00c7040...</td>\n",
       "      <td>[Note when patients have undergone different m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c003</td>\n",
       "      <td>10.1155/2022/2408685</td>\n",
       "      <td>The Choice of Anesthetic Drugs in Outpatient H...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>cit003_1</td>\n",
       "      <td>Research has shown that remimazolam tosylate e...</td>\n",
       "      <td>Research has shown that remimazolam tosylate e...</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiated</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[c836b980-93f4-4dff-ac29-1735fa77227b, 0b41ff6...</td>\n",
       "      <td>[The second study analyzed 325 patients with 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c004</td>\n",
       "      <td>10.1155/2022/4783847</td>\n",
       "      <td>A Fault-Tolerant Structure for Nano-Power Comm...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>cit004_1</td>\n",
       "      <td>if the efficiency of the routing algorithm is ...</td>\n",
       "      <td>If the efficiency of the routing algorithm is ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiated</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1ecb8356-826f-491a-984a-722919362c0e, c0e8850...</td>\n",
       "      <td>[In the table, China's intermediary centrality...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source Citing Article ID         Citing Article DOI  \\\n",
       "0  PubPeer              c001  10.1016/j.est.2021.103553   \n",
       "1  PubPeer              c001  10.1016/j.est.2021.103553   \n",
       "2  PubPeer              c002       10.1155/2022/4601350   \n",
       "3  PubPeer              c003       10.1155/2022/2408685   \n",
       "4  PubPeer              c004       10.1155/2022/4783847   \n",
       "\n",
       "                                Citing Article Title Citing Article Retracted  \\\n",
       "0  Heating a residential building using the heat ...                      Yes   \n",
       "1  Heating a residential building using the heat ...                      Yes   \n",
       "2  Oxidative Potential and Nanoantioxidant Activi...                      Yes   \n",
       "3  The Choice of Anesthetic Drugs in Outpatient H...                      Yes   \n",
       "4  A Fault-Tolerant Structure for Nano-Power Comm...                      Yes   \n",
       "\n",
       "  Citing Article Downloaded       Domain Citation ID  \\\n",
       "0                       Yes  Engineering    cit001_1   \n",
       "1                       Yes  Engineering    cit001_2   \n",
       "2                       Yes    Chemistry    cit002_1   \n",
       "3                       Yes     Medicine    cit003_1   \n",
       "4                       Yes  Engineering    cit004_1   \n",
       "\n",
       "                             Statement with Citation  \\\n",
       "0  Others have aimed to reduce irreversibility or...   \n",
       "1  Some researchers have also studied various hea...   \n",
       "2  The relative content of total flavonoids in th...   \n",
       "3  Research has shown that remimazolam tosylate e...   \n",
       "4  if the efficiency of the routing algorithm is ...   \n",
       "\n",
       "                                 Corrected Statement  ...  \\\n",
       "0  Others have aimed to reduce irreversibility or...  ...   \n",
       "1  Some researchers have also studied various hea...  ...   \n",
       "2  The relative content of total flavonoids in th...  ...   \n",
       "3  Research has shown that remimazolam tosylate e...  ...   \n",
       "4  If the efficiency of the routing algorithm is ...  ...   \n",
       "\n",
       "  Reference Article PDF Available Reference Article Retracted  \\\n",
       "0                             Yes                          No   \n",
       "1                             Yes                          No   \n",
       "2                             Yes                          No   \n",
       "3                             Yes                          No   \n",
       "4                             Yes                          No   \n",
       "\n",
       "  Reference Article Downloaded            Label  Explanation  Error Type  \\\n",
       "0                          Yes  Unsubstantiated   Irrelevant  Irrelevant   \n",
       "1                          Yes  Unsubstantiated   Irrelevant  Irrelevant   \n",
       "2                          Yes  Unsubstantiated   Irrelevant  Irrelevant   \n",
       "3                          Yes  Unsubstantiated   Irrelevant  Irrelevant   \n",
       "4                          Yes  Unsubstantiated   Irrelevant  Irrelevant   \n",
       "\n",
       "  Added Previously Partially Substantiated  \\\n",
       "0    No                                NaN   \n",
       "1    No                                NaN   \n",
       "2    No                                NaN   \n",
       "3    No                                NaN   \n",
       "4    No                                NaN   \n",
       "\n",
       "                                     Top_3_Chunk_IDs  \\\n",
       "0  [15e4928e-d5b4-4358-a37a-0e2eef963320, 4472c31...   \n",
       "1  [1815ea07-43b1-4b3f-bbf0-35876f1f2e2f, cfeb9f2...   \n",
       "2  [3d0ce96f-8ffb-4347-b469-d35015b7ef3a, 00c7040...   \n",
       "3  [c836b980-93f4-4dff-ac29-1735fa77227b, 0b41ff6...   \n",
       "4  [1ecb8356-826f-491a-984a-722919362c0e, c0e8850...   \n",
       "\n",
       "                                   Top_3_Chunk_Texts  \n",
       "0  [68. (8 ) σ 1 σ 17 σ 18 σ 31 σ 30 σ 41 σ 46 σ ...  \n",
       "1  [The evaluations of nanofluid thermo-physical ...  \n",
       "2  [Note when patients have undergone different m...  \n",
       "3  [The second study analyzed 325 patients with 1...  \n",
       "4  [In the table, China's intermediary centrality...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting the models (batch processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def create_batch_files(df, model, number_files=1, ignore_ids=[]):\n",
    "    output_dir = f\"../data/batch_files/{'only_text_' if only_text else ''}{chunking}/{model}\"\n",
    "    # Empty the folder if it exists\n",
    "    if os.path.exists(output_dir):\n",
    "        for filename in os.listdir(output_dir):\n",
    "            file_path = os.path.join(output_dir, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    output_files = []\n",
    "    for i in range(number_files):\n",
    "        output_file = os.path.join(output_dir, f\"prompt_batch_{i}.jsonl\")\n",
    "        # If the file already exists, empty it\n",
    "        open(output_file, \"w\").close()\n",
    "        output_files.append(output_file)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['Reference Article Downloaded'] == 'Yes' and index not in ignore_ids:\n",
    "            prompt = create_prompt(row)\n",
    "            json_sequence = {\n",
    "                \"custom_id\": f\"request-{index}\", \n",
    "                \"method\": \"POST\", \n",
    "                \"url\": \"/v1/chat/completions\", \n",
    "                \"body\": {\n",
    "                    \"model\": model, \n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": prompt\n",
    "                        }\n",
    "                    ],\n",
    "                    \"temperature\": 0,\n",
    "                }\n",
    "            }\n",
    "\n",
    "            output_file = output_files[index % number_files]\n",
    "            with open(output_file, \"a\") as f:\n",
    "                f.write(json.dumps(json_sequence) + \"\\n\")\n",
    "                \n",
    "    # Remove empty output files from list\n",
    "    output_files = [file for file in output_files if os.path.getsize(file) > 0]\n",
    "    \n",
    "    return output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "models = [\"gpt-3.5-turbo-0125\", \"gpt-4.1-nano-2025-04-14\", \"gpt-4.1-mini-2025-04-14\", \"gpt-4.1-2025-04-14\"]\n",
    "model = models[3]\n",
    "\n",
    "os.makedirs(f\"../data/batch_responses/{'only_text_' if only_text else ''}{chunking}\", exist_ok=True)\n",
    "responses_dict_path = f\"../data/batch_responses/{'only_text_' if only_text else ''}{chunking}/{model}_responses_dict_batch.json\"\n",
    "\n",
    "responses_dict = {}\n",
    "try:\n",
    "    with open(responses_dict_path, 'r') as file:\n",
    "        responses_dict = json.load(file)\n",
    "    ids_to_ignore = [int(key) for key in responses_dict.keys()]\n",
    "except FileNotFoundError:\n",
    "    ids_to_ignore = []\n",
    "\n",
    "print(ids_to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_file_paths = create_batch_files(df, model, 5, ids_to_ignore)\n",
    "batch_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of open_ai_key.txt into a variable\n",
    "with open('../open_ai_key.txt', 'r') as file:\n",
    "    open_ai_key = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_batch(batch_id, client):\n",
    "    batch = client.batches.retrieve(batch_id)\n",
    "    print(f\"{batch_id} - Current status: {batch.status}\")\n",
    "    \n",
    "    if batch.status == 'completed' or batch.status == 'failed':\n",
    "        return batch\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "batch_input_files = []\n",
    "batch_creation_responses = []\n",
    "batches = []\n",
    "\n",
    "client = OpenAI(api_key=open_ai_key)\n",
    "\n",
    "def prompt_model_in_batches():\n",
    "    global batch_input_files\n",
    "    global batch_creation_responses\n",
    "    global batches\n",
    "\n",
    "    for batch_file_path in batch_file_paths:\n",
    "        # Creating input file\n",
    "        if os.stat(batch_file_path).st_size == 0:\n",
    "            print(f\"Skipping empty file: {batch_file_path}\")\n",
    "            continue\n",
    "        batch_input_file = client.files.create(\n",
    "            file=open(batch_file_path, \"rb\"),\n",
    "            purpose=\"batch\"\n",
    "        )\n",
    "        print(batch_input_file)\n",
    "        batch_input_files.append(batch_input_file)\n",
    "\n",
    "        # Starting batch job\n",
    "        batch_input_file_id = batch_input_file.id\n",
    "        batch_creation_response = client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "        )\n",
    "        print(\"Started: \" + batch_creation_response.id)\n",
    "\n",
    "        time.sleep(5)\n",
    "        # Check the status of the created batch until it is completed\n",
    "        while True:\n",
    "            batch_id = batch_creation_response.id\n",
    "            batch = check_batch(batch_id, client)\n",
    "            if batch:\n",
    "                if batch.status == \"failed\":\n",
    "                    return\n",
    "                elif batch.status == \"completed\":\n",
    "                    batches.append(batch)\n",
    "                    break\n",
    "            time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT 3.5 Turbo:\n",
    "- 256_20 only_text: 27:22 min\n",
    "- 1024_20: 10:10 \n",
    "- 1024_20 only_text: 34 min (and batch 8 and 9 not successfull due to token limit)\n",
    "\n",
    "GPT 4.1 Nano:\n",
    "- 256_20: 35:10 min\n",
    "- 256_20 only_text: 22:40 min\n",
    "- 1024_20: 15:55 min\n",
    "\n",
    "GPT 4.1 Mini:\n",
    "- 256_20: 19:50 min\n",
    "- 256_20 only_text: 21:40 min\n",
    "- 1024_20: 28:26 min\n",
    "- 1024_20 only_text: 28:20 min (and batch 8 and 9 not successfull due to token limit)\n",
    "\n",
    "GPT 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-VsFPjX7kr4wxPt11XJQivk', bytes=262142, created_at=1752156301, filename='prompt_batch_3.jsonl', object='file', purpose='batch', status='processed', expires_at=None, status_details=None)\n",
      "Started: batch_686fc88df210819081f8054fe973ef2b\n",
      "batch_686fc88df210819081f8054fe973ef2b - Current status: in_progress\n",
      "batch_686fc88df210819081f8054fe973ef2b - Current status: in_progress\n",
      "batch_686fc88df210819081f8054fe973ef2b - Current status: in_progress\n",
      "batch_686fc88df210819081f8054fe973ef2b - Current status: in_progress\n",
      "batch_686fc88df210819081f8054fe973ef2b - Current status: in_progress\n",
      "batch_686fc88df210819081f8054fe973ef2b - Current status: completed\n",
      "FileObject(id='file-4WVBCEUBXdjgcywaMuMgst', bytes=251742, created_at=1752156409, filename='prompt_batch_4.jsonl', object='file', purpose='batch', status='processed', expires_at=None, status_details=None)\n",
      "Started: batch_686fc8f9a6e881909af4eeeb4ed613cb\n",
      "batch_686fc8f9a6e881909af4eeeb4ed613cb - Current status: in_progress\n",
      "batch_686fc8f9a6e881909af4eeeb4ed613cb - Current status: in_progress\n",
      "batch_686fc8f9a6e881909af4eeeb4ed613cb - Current status: in_progress\n",
      "batch_686fc8f9a6e881909af4eeeb4ed613cb - Current status: in_progress\n",
      "batch_686fc8f9a6e881909af4eeeb4ed613cb - Current status: in_progress\n",
      "batch_686fc8f9a6e881909af4eeeb4ed613cb - Current status: finalizing\n",
      "batch_686fc8f9a6e881909af4eeeb4ed613cb - Current status: finalizing\n",
      "batch_686fc8f9a6e881909af4eeeb4ed613cb - Current status: finalizing\n",
      "batch_686fc8f9a6e881909af4eeeb4ed613cb - Current status: finalizing\n",
      "batch_686fc8f9a6e881909af4eeeb4ed613cb - Current status: completed\n",
      "CPU times: user 283 ms, sys: 84.1 ms, total: 367 ms\n",
      "Wall time: 4min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt_model_in_batches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check all open batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=open_ai_key)\n",
    "\n",
    "current_millis = int(time.time())\n",
    "recently = current_millis - 1 * 60 * 60\n",
    "\n",
    "open_batches = client.batches.list()\n",
    "relevant_open_batches = [batch for batch in open_batches if batch.created_at >= recently]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Batch(id='batch_6868096614388190a022996f6be9a17b', completion_window='24h', created_at=1751648614, endpoint='/v1/chat/completions', input_file_id='file-UfAtZGcxmckxTpS1aAMXJ5', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4.1-mini-2025-04-14 in organization org-6SCiN9rjR6tU38WJ0DavgNRs. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list'), expired_at=None, expires_at=1751735014, failed_at=1751648615, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)),\n",
       " Batch(id='batch_686808c76bc081908c33aa7cf8e00f6f', completion_window='24h', created_at=1751648455, endpoint='/v1/chat/completions', input_file_id='file-CGFXQgJ9pC8oCg6VqtNFKD', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4.1-nano-2025-04-14 in organization org-6SCiN9rjR6tU38WJ0DavgNRs. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list'), expired_at=None, expires_at=1751734855, failed_at=1751648457, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)),\n",
       " Batch(id='batch_6867fd776fb8819088ca3c4349cf13b2', completion_window='24h', created_at=1751645559, endpoint='/v1/chat/completions', input_file_id='file-Tue48DgSXc3HLbUG2QRWwr', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1751731959, failed_at=None, finalizing_at=None, in_progress_at=1751645560, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=24))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(relevant_open_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": \"batch_req_68678a072b3881908b17d5aff3211ac4\", \"custom_id\": \"request-0\", \"response\": {\"status_code\": 200, \"request_id\": \"89ad89cfcb2a16e6f4cfc4ba768a5351\", \"body\": {\"id\": \"chatcmpl-BpVcqfN3e1zWesxuClqhceQMoxQyt\", \"object\": \"chat.completion\", \"created\": 1751615996, \"model\": \"gpt-3.5-turbo-0125\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\\n    \\\\\"label\\\\\": \\\\\"Unsubstantiated\\\\\",\\\\n    \\\\\"explanation\\\\\": \\\\\"The reference article does not support the statement about reducing irreversibility or optimizing energy-consumed devices, as it focuses on fault analysis of three-phase induction motors.\\\\\"\\\\n}\", \"refusal\": null, \"annotations\": []}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 1163, \"completion_tokens\": 51, \"total_tokens\": 1214, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": null}}, \"error\": null}\\n{\"id\": \"batch_req_68678a079fb88190961dd850340dc0b9\", \"custom_id\": \"request-20\", \"response\": {\"status_code\": 200, \"request_id\": \"e8af6813d3643935d8bf9ec498287672\", \"body\": {\"id\": \"chatcmpl-BpVcr05qjTyf5efwscxSlmTMXP55I\", \"object\": \"chat.completion\", \"created\": 1751615997, \"model\": \"gpt-3.5-turbo-0125\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\\n    \\\\\"label\\\\\": \\\\\"Unsubstantiated\\\\\",\\\\n    \\\\\"explanation\\\\\": \\\\\"The reference article focuses on cyberattack detection using unsupervised autoencoders and Gaussian mixture models, which is unrelated to urban planning and construction discussed in the citation statement.\\\\\"\\\\n}\", \"refusal\": null, \"annotations\": []}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 1343, \"completion_tokens\": 52, \"total_tokens\": 1395, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": null}}, \"error\": null}\\n{\"id\": \"batch_req_68678a0814bc8190b68285f7d6f5c817\", \"custom_id\": \"request-40\", \"response\": {\"status_code\": 200, \"request_id\": \"a601c954e7150de1d345ea7ba0bfe34d\", \"body\": {\"id\": \"chatcmpl-BpVcs9bzdCU00hwEZd9AQ0Mb9wTz5\", \"object\": \"chat.completion\", \"created\": 1751615998, \"model\": \"gpt-3.5-turbo-0125\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\\n    \\\\\"label\\\\\": \\\\\"Unsubstantiated\\\\\",\\\\n    \\\\\"explanation\\\\\": \\\\\"The reference article does not support the statement about coordination chemistry providing compounds with multiple mechanisms associated with DNA binding, redox reactivity, and different geometries specific to metals. The reference article focuses on bug report classification and data reduction techniques in software maintenance, which is unrelated to the statement.\\\\\"\\\\n}\", \"refusal\": null, \"annotations\": []}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 1246, \"completion_tokens\": 75, \"total_tokens\": 1321, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": null}}, \"error\": null}\\n{\"id\": \"batch_req_68678a088fdc8190a34f3700a0ff284f\", \"custom_id\": \"request-60\", \"response\": {\"status_code\": 200, \"request_id\": \"3e7eabd34ad9c5a587f5b5f750b2c083\", \"body\": {\"id\": \"chatcmpl-BpVcuouSvhw4NBc4nlRYVBQvSLp6I\", \"object\": \"chat.completion\", \"created\": 1751616000, \"model\": \"gpt-3.5-turbo-0125\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\\n    \\\\\"label\\\\\": \\\\\"Unsubstantiated\\\\\",\\\\n    \\\\\"explanation\\\\\": \\\\\"The reference article does not support the statement about a professional team with theoretical knowledge and practical skills in education management. The reference article focuses on big data technology in vehicular ad hoc networks, not on education management.\\\\\"\\\\n}\", \"refusal\": null, \"annotations\": []}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 1140, \"completion_tokens\": 60, \"total_tokens\": 1200, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": null}}, \"error\": null}\\n{\"id\": \"batch_req_68678a0904148190af87189a83929869\", \"custom_id\": \"request-80\", \"response\": {\"status_code\": 200, \"request_id\": \"1f427508934bdc2eae9fb206dbed797f\", \"body\": {\"id\": \"chatcmpl-BpVcxQW2zjytcTqRqVCC0KqtsbDOW\", \"object\": \"chat.completion\", \"created\": 1751616003, \"model\": \"gpt-3.5-turbo-0125\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\\n    \\\\\"label\\\\\": \\\\\"Substantiated\\\\\",\\\\n    \\\\\"explanation\\\\\": \\\\\"The reference article discusses the gap junction gene and protein families, including connexins, innexins, and pannexins, which supports the citation statement about characterizing the possible mechanism of action for extracellular loop peptides.\\\\\"\\\\n}\", \"refusal\": null, \"annotations\": []}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 1058, \"completion_tokens\": 63, \"total_tokens\": 1121, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": null}}, \"error\": null}\\n{\"id\": \"batch_req_68678a097eb481908b8f3987355aeb1b\", \"custom_id\": \"request-100\", \"response\": {\"status_code\": 200, \"request_id\": \"d5edf9a97fede0da727bd0a82c07267f\", \"body\": {\"id\": \"chatcmpl-BpVctY5krEqUG1EPfwPARQXuM6rtp\", \"object\": \"chat.completion\", \"created\": 1751615999, \"model\": \"gpt-3.5-turbo-0125\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\\n    \\\\\"label\\\\\": \\\\\"Substantiated\\\\\",\\\\n    \\\\\"explanation\\\\\": \\\\\"The reference article supports the statement by providing information on the effect of ATP around its physiological concentration range complexed with Mg2+ ions.\\\\\"\\\\n}\", \"refusal\": null, \"annotations\": []}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 1629, \"completion_tokens\": 44, \"total_tokens\": 1673, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": null}}, \"error\": null}\\n{\"id\": \"batch_req_68678a09f8588190a2ea83862f683677\", \"custom_id\": \"request-120\", \"response\": {\"status_code\": 200, \"request_id\": \"de11ba5e772731fbd4357ad7ace58cc4\", \"body\": {\"id\": \"chatcmpl-BpVct5MrUfgUxt7E9lHjpoQnFwPA6\", \"object\": \"chat.completion\", \"created\": 1751615999, \"model\": \"gpt-3.5-turbo-0125\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\\n    \\\\\"label\\\\\": \\\\\"Unsubstantiated\\\\\",\\\\n    \\\\\"explanation\\\\\": \\\\\"The reference article discusses the treatment of singularities in Hartree-Fock and exact-exchange Kohn-Sham methods for solids, but does not specifically mention the acceleration of convergence for PBE0 as stated in the citation statement.\\\\\"\\\\n}\", \"refusal\": null, \"annotations\": []}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 1316, \"completion_tokens\": 64, \"total_tokens\": 1380, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": null}}, \"error\": null}\\n{\"id\": \"batch_req_68678a0a6ec081908e9251cd8bc81d89\", \"custom_id\": \"request-140\", \"response\": {\"status_code\": 200, \"request_id\": \"9f60e041e698945cd067bbe088fb23ef\", \"body\": {\"id\": \"chatcmpl-BpVctZkvSEGMmtT1K5GmrNdumcPek\", \"object\": \"chat.completion\", \"created\": 1751615999, \"model\": \"gpt-3.5-turbo-0125\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\\n    \\\\\"label\\\\\": \\\\\"Substantiated\\\\\",\\\\n    \\\\\"explanation\\\\\": \\\\\"The reference article supports the citation statement by mentioning polarization gating as a method for generating attosecond pulses, which aligns with the information provided in the citation statement.\\\\\"\\\\n}\", \"refusal\": null, \"annotations\": []}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 1333, \"completion_tokens\": 50, \"total_tokens\": 1383, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": null}}, \"error\": null}\\n{\"id\": \"batch_req_68678a0ae3388190aeeb18d5d63a79d9\", \"custom_id\": \"request-160\", \"response\": {\"status_code\": 200, \"request_id\": \"a446011328cefedc6be4b8c570dfcbb1\", \"body\": {\"id\": \"chatcmpl-BpVcvyaZIsylAA07DxEHpX26y4tkL\", \"object\": \"chat.completion\", \"created\": 1751616001, \"model\": \"gpt-3.5-turbo-0125\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\\n    \\\\\"label\\\\\": \\\\\"Substantiated\\\\\",\\\\n    \\\\\"explanation\\\\\": \\\\\"The reference article supports the statement that the expression levels of mRNA species can be used to classify cell types and order cell states by demonstrating how single-cell analyses provide insights into the mechanistic and network effects of genetic variability on gene expression.\\\\\"\\\\n}\", \"refusal\": null, \"annotations\": []}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 1295, \"completion_tokens\": 63, \"total_tokens\": 1358, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": null}}, \"error\": null}\\n{\"id\": \"batch_req_68678a0b58008190801e27daabe7ed54\", \"custom_id\": \"request-180\", \"response\": {\"status_code\": 200, \"request_id\": \"88ef66906fe668b00f1aba7a1c532596\", \"body\": {\"id\": \"chatcmpl-BpVcxmbp846n52agHadoo6aIaCYzS\", \"object\": \"chat.completion\", \"created\": 1751616003, \"model\": \"gpt-3.5-turbo-0125\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\\n  \\\\\"label\\\\\": \\\\\"Substantiated\\\\\",\\\\n  \\\\\"explanation\\\\\": \\\\\"The reference article supports the citation statement by explaining that the quantum noncloning theorem prohibits the amplification of quantum states, including photons, ruling out the possibility of producing several copies of a quantum system with the same state as the original.\\\\\"\\\\n}\", \"refusal\": null, \"annotations\": []}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 1377, \"completion_tokens\": 64, \"total_tokens\": 1441, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": null}}, \"error\": null}\\n{\"id\": \"batch_req_68678a0bcbe08190b4c82e918666e6eb\", \"custom_id\": \"request-200\", \"response\": {\"status_code\": 200, \"request_id\": \"c5099cc668d362dfa3591e9e8e8ba1af\", \"body\": {\"id\": \"chatcmpl-BpVcvOTB1RPjJKpOceIccBlKOyAx7\", \"object\": \"chat.completion\", \"created\": 1751616001, \"model\": \"gpt-3.5-turbo-0125\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\\n    \\\\\"label\\\\\": \\\\\"Substantiated\\\\\",\\\\n    \\\\\"explanation\\\\\": \\\\\"The reference article supports the statement as it discusses the development of soft network composite materials with stress/strain responses that can be tailored precisely, which aligns with the development of flexible and stretchable devices mentioned in the citation statement.\\\\\"\\\\n}\", \"refusal\": null, \"annotations\": []}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 1100, \"completion_tokens\": 62, \"total_tokens\": 1162, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": null}}, \"error\": null}\\n{\"id\": \"batch_req_68678a0c40048190a7fd0d8eb3a012f0\", \"custom_id\": \"request-220\", \"response\": {\"status_code\": 200, \"request_id\": \"7817cb21a79677b139eb85e5041ada3e\", \"body\": {\"id\": \"chatcmpl-BpVcv4VZHZVuUK9ZFVf7N6cBr3h8I\", \"object\": \"chat.completion\", \"created\": 1751616001, \"model\": \"gpt-3.5-turbo-0125\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\\n    \\\\\"label\\\\\": \\\\\"Unsubstantiated\\\\\",\\\\n    \\\\\"explanation\\\\\": \\\\\"The reference article discusses the biogeography of a human oral microbiome at the micron scale, focusing on dental plaque, and does not provide direct support for the statement about microbial communities associated with specific sites on and within numerous plants and animals.\\\\\"\\\\n}\", \"refusal\": null, \"annotations\": []}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 1446, \"completion_tokens\": 66, \"total_tokens\": 1512, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": null}}, \"error\": null}\\n{\"id\": \"batch_req_68678a0cb9348190ac038a737e86fe04\", \"custom_id\": \"request-240\", \"response\": {\"status_code\": 200, \"request_id\": \"31bee3791ab4c201fc5acea4a5d7af28\", \"body\": {\"id\": \"chatcmpl-BpVcwkAxBg14bXoaKCO1YVoDHxu62\", \"object\": \"chat.completion\", \"created\": 1751616002, \"model\": \"gpt-3.5-turbo-0125\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\\n    \\\\\"label\\\\\": \\\\\"Substantiated\\\\\",\\\\n    \\\\\"explanation\\\\\": \\\\\"The reference article fully supports the citation statement by discussing the eigenstate thermalization hypothesis (ETH) and its alternatives, which are directly related to the concept of statistical ensembles arising from the unitary time evolution of an isolated quantum system.\\\\\"\\\\n}\", \"refusal\": null, \"annotations\": []}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 1273, \"completion_tokens\": 64, \"total_tokens\": 1337, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": null}}, \"error\": null}\\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.content(relevant_open_batches[0].output_file_id).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConflictError",
     "evalue": "Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'completed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConflictError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcancel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_67e3cf592eb081908cd64e5e1dc55fa0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master_thesis/citation-verification/.venv/lib/python3.10/site-packages/openai/resources/batches.py:229\u001b[0m, in \u001b[0;36mBatches.cancel\u001b[0;34m(self, batch_id, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch_id:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a non-empty value for `batch_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/batches/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbatch_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/cancel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master_thesis/citation-verification/.venv/lib/python3.10/site-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/master_thesis/citation-verification/.venv/lib/python3.10/site-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master_thesis/citation-verification/.venv/lib/python3.10/site-packages/openai/_base_client.py:1008\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1007\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/master_thesis/citation-verification/.venv/lib/python3.10/site-packages/openai/_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master_thesis/citation-verification/.venv/lib/python3.10/site-packages/openai/_base_client.py:1008\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1007\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/master_thesis/citation-verification/.venv/lib/python3.10/site-packages/openai/_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master_thesis/citation-verification/.venv/lib/python3.10/site-packages/openai/_base_client.py:1023\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1022\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1026\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1027\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1032\u001b[0m )\n",
      "\u001b[0;31mConflictError\u001b[0m: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'completed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "# client.batches.cancel(\"batch_67e3cf592eb081908cd64e5e1dc55fa0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the batch status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def wait_for_batch_completion(batch_id, client, interval=10):\n",
    "    while True:\n",
    "        batch = check_batch(batch_id, client)\n",
    "        if batch != None:\n",
    "            return batch\n",
    "        time.sleep(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_68678417bf4c819085e0d77c012d5a7a - Current status: completed\n"
     ]
    }
   ],
   "source": [
    "batch = wait_for_batch_completion(\"batch_68678417bf4c819085e0d77c012d5a7a\", client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_686789f989bc8190b9cfc3a12dc8ccdc - Current status: completed\n"
     ]
    }
   ],
   "source": [
    "batch = check_batch(\"batch_686789f989bc8190b9cfc3a12dc8ccdc\", client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_68678417bf4c819085e0d77c012d5a7a', completion_window='24h', created_at=1751614487, endpoint='/v1/chat/completions', input_file_id='file-TubVrLSjHxewNncTaHNShi', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1751614569, error_file_id='file-39tX7oztfkdnqiNEpYDUMb', errors=None, expired_at=None, expires_at=1751700887, failed_at=None, finalizing_at=1751614556, in_progress_at=1751614490, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=25, total=25))\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# save responds of completed batches\n",
    "for batch in batches:\n",
    "    if batch.status != \"completed\":\n",
    "        continue\n",
    "    model_responses = client.files.content(batch.output_file_id).text\n",
    "\n",
    "    # Parse the model_responses into a list of objects\n",
    "    responses_list = [json.loads(line) for line in model_responses.splitlines()]\n",
    "    # print(responses_list)\n",
    "\n",
    "    try:\n",
    "        for response in responses_list:\n",
    "            responses_dict[int(response['custom_id'].split('-')[1])] = response\n",
    "            responses_dict = dict(sorted(responses_dict.items(), key=lambda item: int(item[0])))\n",
    "    except NameError:\n",
    "        responses_dict = {int(response['custom_id'].split('-')[1]): response for response in responses_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save responses_dict to a JSON file\n",
    "with open(responses_dict_path, 'w') as file:\n",
    "    json.dump(responses_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save responds to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in the dataframe to store the responses\n",
    "if 'Model Classification' not in df.columns:\n",
    "    df['Model Classification'] = None\n",
    "\n",
    "# Iterate through the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    if row['Reference Article Downloaded'] == 'Yes':\n",
    "        i = index\n",
    "        if i not in responses_dict:\n",
    "            i = str(i)\n",
    "        model_response = responses_dict[i]['response']['body']['choices'][0]['message']['content']\n",
    "        \n",
    "        # Save the response to the new column\n",
    "        df.at[index, 'Model Classification'] = model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_path = f\"../data/dfs/{'only_text_' if only_text else ''}{chunking}/{model}/\"\n",
    "os.makedirs(dfs_path, exist_ok=True)\n",
    "df.to_pickle(f\"{dfs_path}ReferenceErrorDetection_data_with_prompt_results.pkl\")\n",
    "df.to_excel(f\"{dfs_path}ReferenceErrorDetection_data_with_prompt_results.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
