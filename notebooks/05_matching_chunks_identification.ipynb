{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the 3 top matching chunks using LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlamaIndex:\n",
    "- Github: https://github.com/run-llama/llama_index\n",
    "- Documentation: https://docs.llamaindex.ai/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the xlsx data into a pandas dataframe\n",
    "df = pd.read_excel('../data/ReferenceErrorDetection_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Citing Article ID</th>\n",
       "      <th>Citing Article DOI</th>\n",
       "      <th>Citing Article Title</th>\n",
       "      <th>Citing Article Retracted</th>\n",
       "      <th>Citing Article Downloaded</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Statement with Citation</th>\n",
       "      <th>Reference Article ID</th>\n",
       "      <th>Reference Article DOI</th>\n",
       "      <th>Reference Article Title</th>\n",
       "      <th>Reference Article Abstract</th>\n",
       "      <th>Reference Article PDF Available</th>\n",
       "      <th>Reference Article Retracted</th>\n",
       "      <th>Reference Article Downloaded</th>\n",
       "      <th>Label</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c001</td>\n",
       "      <td>10.1016/j.est.2021.103553</td>\n",
       "      <td>Heating a residential building using the heat ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Others have aimed to reduce irreversibility or...</td>\n",
       "      <td>r001</td>\n",
       "      <td>10.1155/2021/2087027</td>\n",
       "      <td>A Fault Analysis Method for Three-Phase Induct...</td>\n",
       "      <td>The fault prediction and abductive fault diagn...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiate</td>\n",
       "      <td>Irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c001</td>\n",
       "      <td>10.1016/j.est.2021.103553</td>\n",
       "      <td>Heating a residential building using the heat ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Some researchers have also studied various hea...</td>\n",
       "      <td>r002</td>\n",
       "      <td>10.1016/j.physa.2018.12.031</td>\n",
       "      <td>Develop 24 dissimilar ANNs by suitable archite...</td>\n",
       "      <td>The artificial neural network optimization met...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiate</td>\n",
       "      <td>Irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c002</td>\n",
       "      <td>10.1155/2022/4601350</td>\n",
       "      <td>Oxidative Potential and Nanoantioxidant Activi...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>The relative content of total flavonoids in th...</td>\n",
       "      <td>r003</td>\n",
       "      <td>10.1088/1742-6596/1937/1/012038</td>\n",
       "      <td>Lipid Data Acquisition for devices Treatment o...</td>\n",
       "      <td>Recently, the widespread deployment of smart p...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiate</td>\n",
       "      <td>Irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c003</td>\n",
       "      <td>10.1155/2022/2408685</td>\n",
       "      <td>The Choice of Anesthetic Drugs in Outpatient H...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Research has shown that remimazolam tosylate e...</td>\n",
       "      <td>r004</td>\n",
       "      <td>10.1186/s12871-018-0543-3</td>\n",
       "      <td>Effect of propofol on breast cancer cell, the ...</td>\n",
       "      <td>Breast cancer is the second leading cause of c...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiate</td>\n",
       "      <td>Irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c004</td>\n",
       "      <td>10.1155/2022/4783847</td>\n",
       "      <td>A Fault-Tolerant Structure for Nano-Power Comm...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>if the efficiency of the routing algorithm is ...</td>\n",
       "      <td>r005</td>\n",
       "      <td>10.36410/jcpr.2022.23.3.312</td>\n",
       "      <td>Analysis and research hotspots of ceramic mate...</td>\n",
       "      <td>From the perspective of scientometrics, comb t...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiate</td>\n",
       "      <td>Irrelevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source Citing Article ID         Citing Article DOI  \\\n",
       "0  PubPeer              c001  10.1016/j.est.2021.103553   \n",
       "1  PubPeer              c001  10.1016/j.est.2021.103553   \n",
       "2  PubPeer              c002       10.1155/2022/4601350   \n",
       "3  PubPeer              c003       10.1155/2022/2408685   \n",
       "4  PubPeer              c004       10.1155/2022/4783847   \n",
       "\n",
       "                                Citing Article Title Citing Article Retracted  \\\n",
       "0  Heating a residential building using the heat ...                      Yes   \n",
       "1  Heating a residential building using the heat ...                      Yes   \n",
       "2  Oxidative Potential and Nanoantioxidant Activi...                      Yes   \n",
       "3  The Choice of Anesthetic Drugs in Outpatient H...                      Yes   \n",
       "4  A Fault-Tolerant Structure for Nano-Power Comm...                      Yes   \n",
       "\n",
       "  Citing Article Downloaded       Domain  \\\n",
       "0                       Yes  Engineering   \n",
       "1                       Yes  Engineering   \n",
       "2                       Yes    Chemistry   \n",
       "3                       Yes     Medicine   \n",
       "4                       Yes  Engineering   \n",
       "\n",
       "                             Statement with Citation Reference Article ID  \\\n",
       "0  Others have aimed to reduce irreversibility or...                 r001   \n",
       "1  Some researchers have also studied various hea...                 r002   \n",
       "2  The relative content of total flavonoids in th...                 r003   \n",
       "3  Research has shown that remimazolam tosylate e...                 r004   \n",
       "4  if the efficiency of the routing algorithm is ...                 r005   \n",
       "\n",
       "             Reference Article DOI  \\\n",
       "0             10.1155/2021/2087027   \n",
       "1      10.1016/j.physa.2018.12.031   \n",
       "2  10.1088/1742-6596/1937/1/012038   \n",
       "3        10.1186/s12871-018-0543-3   \n",
       "4      10.36410/jcpr.2022.23.3.312   \n",
       "\n",
       "                             Reference Article Title  \\\n",
       "0  A Fault Analysis Method for Three-Phase Induct...   \n",
       "1  Develop 24 dissimilar ANNs by suitable archite...   \n",
       "2  Lipid Data Acquisition for devices Treatment o...   \n",
       "3  Effect of propofol on breast cancer cell, the ...   \n",
       "4  Analysis and research hotspots of ceramic mate...   \n",
       "\n",
       "                          Reference Article Abstract  \\\n",
       "0  The fault prediction and abductive fault diagn...   \n",
       "1  The artificial neural network optimization met...   \n",
       "2  Recently, the widespread deployment of smart p...   \n",
       "3  Breast cancer is the second leading cause of c...   \n",
       "4  From the perspective of scientometrics, comb t...   \n",
       "\n",
       "  Reference Article PDF Available Reference Article Retracted  \\\n",
       "0                             Yes                          No   \n",
       "1                             Yes                          No   \n",
       "2                             Yes                          No   \n",
       "3                             Yes                          No   \n",
       "4                             Yes                          No   \n",
       "\n",
       "  Reference Article Downloaded           Label Explanation  \n",
       "0                          Yes  Unsubstantiate  Irrelevant  \n",
       "1                          Yes  Unsubstantiate  Irrelevant  \n",
       "2                          Yes  Unsubstantiate  Irrelevant  \n",
       "3                          Yes  Unsubstantiate  Irrelevant  \n",
       "4                          Yes  Unsubstantiate  Irrelevant  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get text from reference article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "grobid_model = \"full_model_texts\"\n",
    "extension = \"txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def get_file_path(reference_article_id):\n",
    "    # Construct the file path pattern using the Reference Article ID of the first entry\n",
    "    file_pattern = f\"../data/extractions/{grobid_model}/{reference_article_id}*.{extension}\"\n",
    "\n",
    "    # Find the file that matches the pattern\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    if file_list:\n",
    "        file_path = file_list[0]\n",
    "        return file_path\n",
    "    else: \n",
    "        print(\"No matching file found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def get_reference_text(reference_article_id):\n",
    "    global extension\n",
    "    \n",
    "    # Get the file path\n",
    "    file_path = get_file_path(reference_article_id)\n",
    "    \n",
    "    if file_path:\n",
    "        if extension == \"txt\":\n",
    "            # Read the text file\n",
    "            with open(file_path, 'r') as file:\n",
    "                reference_text = file.read()\n",
    "            return reference_text\n",
    "\n",
    "        elif extension == \"xml\":\n",
    "            # Parse the XML file\n",
    "            tree = ET.parse(file_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Extract the text content from the XML file\n",
    "            reference_text = ''.join(root.itertext())\n",
    "            return reference_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set OpenAI key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of open_ai_key.txt into a variable\n",
    "with open('../open_ai_key.txt', 'r') as file:\n",
    "    open_ai_key = file.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up vector index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading or generating index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = \"te3s\" # / \"te3s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"te3l\":\n",
    "    model_embeddings = \"text-embedding-3-large\"\n",
    "elif embedding == \"te3s\":\n",
    "    model_embeddings = \"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(model=model_embeddings, api_key=open_ai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, Document\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "def create_index(reference_text, chunk_size, chunk_overlap):\n",
    "    # create the pipeline with transformations\n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[\n",
    "            SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap),\n",
    "            OpenAIEmbedding(model=model_embeddings, api_key=open_ai_key)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # run the pipeline\n",
    "    nodes = pipeline.run(documents=[Document(text=reference_text)])\n",
    "    index = VectorStoreIndex(nodes)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "def create_chunks(text, chunk_size=256, chunk_overlap=20):\n",
    "    token_text_splitter = TokenTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = token_text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_with_chunking_first(reference_text, chunk_size, chunk_overlap):\n",
    "    reference_chunks = create_chunks(reference_text, chunk_size, chunk_overlap)\n",
    "    documents = [Document(text=chunk) for chunk in reference_chunks]\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "def load_or_create_index(article_id, reference_text, no_prev_chunking, chunk_size=256, chunk_overlap=20):\n",
    "    index_path = f\"../data/vector_indices/{embedding}{'_no_prev_chunking' if no_prev_chunking else ''}/{grobid_model}/{article_id}/\"\n",
    "    index = None\n",
    "\n",
    "    try:\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
    "        index = load_index_from_storage(storage_context)\n",
    "        print(article_id + \": Loaded existing index.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(article_id + \": Creating a new index.\")\n",
    "        try: \n",
    "            if no_prev_chunking:\n",
    "                index = create_index(reference_text, chunk_size, chunk_overlap)\n",
    "            else:\n",
    "                index = create_index_with_chunking_first(reference_text, chunk_size, chunk_overlap)\n",
    "            index.storage_context.persist(persist_dir=index_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(article_id + \": Failed to create index.\")\n",
    "            print(reference_text)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Indices for all reference articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/home/ibelter/master_thesis/citation-verification/notebooks/../data/vector_indices/te3s/full_model_texts/r071/docstore.json'\n",
      "r071: Creating a new index.\n",
      "[Errno 2] No such file or directory: '/home/ibelter/master_thesis/citation-verification/notebooks/../data/vector_indices/te3s/full_model_texts/r075/docstore.json'\n",
      "r075: Creating a new index.\n",
      "[Errno 2] No such file or directory: '/home/ibelter/master_thesis/citation-verification/notebooks/../data/vector_indices/te3s/full_model_texts/r147/docstore.json'\n",
      "r147: Creating a new index.\n"
     ]
    }
   ],
   "source": [
    "ids_to_index = [\"r071\", \"r075\", \"r147\"]\n",
    "no_prev_chunking = False\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    if row['Reference Article Downloaded'] == 'Yes':\n",
    "        reference_article_id = row['Reference Article ID']\n",
    "        if reference_article_id and (len(ids_to_index) == 0 or reference_article_id in ids_to_index):\n",
    "            reference_text = get_reference_text(reference_article_id)\n",
    "            index = load_or_create_index(reference_article_id, reference_text, no_prev_chunking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying top 3 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "def get_top_k_similar_chunks(statement, index, k=3):\n",
    "    retriever = VectorIndexRetriever(\n",
    "        index=index,\n",
    "        similarity_top_k=k,\n",
    "    )\n",
    "    retrieved_nodes = retriever.retrieve(statement)\n",
    "    return retrieved_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def save_similar_chunks(doc_ids, reference_id):\n",
    "    file_path = f\"../data/similar_chunks/{embedding}{'_no_prev_chunking' if no_prev_chunking else ''}/{grobid_model}/{reference_id}.json\"\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(doc_ids, file)\n",
    "\n",
    "def load_similar_chunks(reference_id):\n",
    "    file_path = f\"../data/similar_chunks/{embedding}{'_no_prev_chunking' if no_prev_chunking else ''}/{grobid_model}/{reference_id}.json\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        doc_ids = json.load(file)\n",
    "    return doc_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the document ids and text contents of the top k chunks of all reference articles to the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_ids(response):\n",
    "    doc_ids = []\n",
    "    for node in response:\n",
    "        doc_ids.append(node.dict()['node']['id_'])\n",
    "    return doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_top_k_chunk_ids(df, no_prev_chunking, k=3):\n",
    "    for _, row in df.iterrows():\n",
    "        if row['Reference Article Downloaded'] == 'Yes':\n",
    "            reference_article_id = row['Reference Article ID']\n",
    "            print(f\"------ Starting {reference_article_id} ------\")\n",
    "            \n",
    "            # Try to load similar chunks first\n",
    "            try:\n",
    "                doc_ids = load_similar_chunks(reference_article_id)\n",
    "                print(\"Loaded similar chunks successfully.\")\n",
    "            except FileNotFoundError:\n",
    "                # Load reference text and create chunks\n",
    "                reference_text = get_reference_text(reference_article_id)\n",
    "                \n",
    "                # Load or create index\n",
    "                index = load_or_create_index(reference_article_id, reference_text, no_prev_chunking)\n",
    "                \n",
    "                # Get the statement and retrieve top chunks\n",
    "                statement = row[\"Statement with Citation\"]\n",
    "                print(\"Receiving top chunks\")\n",
    "\n",
    "                try:\n",
    "                    response = get_top_k_similar_chunks(statement, index, k)\n",
    "                    doc_ids = get_doc_ids(response)\n",
    "                    \n",
    "                    # Save the top chunks\n",
    "                    print(\"Saving top chunks\")\n",
    "                    save_similar_chunks(doc_ids, reference_article_id)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(\"Failed to get top chunks.\")\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Starting r001 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r002 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r003 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r004 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r005 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r006 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r007 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r008 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r009 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r010 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r011 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r012 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r013 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r013 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r014 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r015 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r005 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r017 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r018 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r019 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r020 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r021 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r022 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r023 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r024 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r013 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r025 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r026 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r027 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r028 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r029 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r030 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r031 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r032 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r033 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r034 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r035 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r036 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r037 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r038 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r039 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r040 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r041 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r042 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r043 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r044 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r045 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r046 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r047 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r048 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r049 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r050 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r051 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r052 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r053 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r051 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r055 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r056 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r057 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r058 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r059 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r060 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r061 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r062 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r063 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r064 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r065 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r066 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r067 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r068 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r069 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r070 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r071 ------\n",
      "r071: Loaded existing index.\n",
      "Receiving top chunks\n",
      "Saving top chunks\n",
      "\n",
      "------ Starting r072 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r074 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r075 ------\n",
      "r075: Loaded existing index.\n",
      "Receiving top chunks\n",
      "Saving top chunks\n",
      "\n",
      "------ Starting r076 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r077 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r078 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r079 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r080 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r081 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r081 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r082 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r083 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r084 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r085 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r086 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r087 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r087 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r087 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r088 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r089 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r090 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r091 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r092 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r093 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r094 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r095 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r096 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r097 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r098 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r099 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r100 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r101 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r102 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r103 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r104 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r105 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r106 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r107 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r108 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r109 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r110 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r111 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r112 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r113 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r114 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r115 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r116 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r117 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r118 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r119 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r120 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r121 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r122 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r123 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r124 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r125 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r126 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r127 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r128 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r129 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r130 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r131 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r132 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r133 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r134 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r135 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r136 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r137 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r138 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r139 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r140 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r141 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r142 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r143 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r144 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r145 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r146 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r147 ------\n",
      "r147: Loaded existing index.\n",
      "Receiving top chunks\n",
      "Saving top chunks\n",
      "\n",
      "------ Starting r148 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r149 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r150 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r151 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r152 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r153 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r154 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r155 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r156 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r157 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r158 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r159 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r160 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r161 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r162 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r163 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r164 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r165 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r166 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r167 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r168 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r169 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r170 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r171 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r172 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r173 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r174 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r175 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r176 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r177 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r178 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r179 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r180 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r181 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r182 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r183 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r184 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r185 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r186 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r187 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r188 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r189 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r190 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r191 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r192 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r193 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r194 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r195 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r196 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r197 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r198 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r199 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r200 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r201 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r202 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r203 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r204 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r205 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r206 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r207 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r208 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r209 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r210 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r211 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r212 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r213 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r214 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r215 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r216 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r217 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r218 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r219 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r220 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r221 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r222 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r223 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r224 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r225 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r226 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r227 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r228 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r229 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r230 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r231 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r232 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r233 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r234 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r235 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r236 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r237 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r238 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r239 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r240 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r241 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r242 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n",
      "------ Starting r243 ------\n",
      "Loaded similar chunks successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_prev_chunking = False\n",
    "save_top_k_chunk_ids(df, no_prev_chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output_dir = f\"../data/dfs/{embedding}{'_no_prev_chunking' if no_prev_chunking else ''}/{grobid_model}/\"\n",
    "df2 = pd.read_pickle(os.path.join(output_dir, f\"ReferenceErrorDetection_data_with_chunk_info.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_top_k_chunk_ids_and_texts_to_df(df, k=3):\n",
    "    doc_ids_list = []\n",
    "    doc_texts_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['Reference Article Downloaded'] == 'Yes':\n",
    "            reference_article_id = row['Reference Article ID']\n",
    "\n",
    "            if len(ids_to_index) != 0 and reference_article_id not in ids_to_index:\n",
    "                doc_ids_list.append(row[f'Top_{k}_Chunk_IDs'])\n",
    "                doc_texts_list.append(row[f'Top_{k}_Chunk_Texts'])\n",
    "                continue\n",
    "            \n",
    "            print(f\"------ Starting {reference_article_id} ------\")\n",
    "\n",
    "            # load index\n",
    "            index_path = f\"../data/vector_indices/{embedding}{'_no_prev_chunking' if no_prev_chunking else ''}/{grobid_model}/{reference_article_id}/\"\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "\n",
    "            # load similar chunks\n",
    "            doc_ids = load_similar_chunks(reference_article_id)\n",
    "            doc_texts = [index.docstore.docs[doc_id].text for doc_id in doc_ids]\n",
    "\n",
    "            # add to lists\n",
    "            doc_ids_list.append(doc_ids)\n",
    "            doc_texts_list.append(doc_texts)\n",
    "        else:\n",
    "            doc_ids_list.append(None)\n",
    "            doc_texts_list.append(None)\n",
    "    \n",
    "    df[f'Top_{k}_Chunk_IDs'] = doc_ids_list\n",
    "    df[f'Top_{k}_Chunk_Texts'] = doc_texts_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Starting r071 ------\n",
      "------ Starting r075 ------\n",
      "------ Starting r147 ------\n"
     ]
    }
   ],
   "source": [
    "ids_to_index = [\"r071\", \"r075\", \"r147\"]\n",
    "df2 = add_top_k_chunk_ids_and_texts_to_df(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Citing Article ID</th>\n",
       "      <th>Citing Article DOI</th>\n",
       "      <th>Citing Article Title</th>\n",
       "      <th>Citing Article Retracted</th>\n",
       "      <th>Citing Article Downloaded</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Statement with Citation</th>\n",
       "      <th>Reference Article ID</th>\n",
       "      <th>Reference Article DOI</th>\n",
       "      <th>Reference Article Title</th>\n",
       "      <th>Reference Article Abstract</th>\n",
       "      <th>Reference Article PDF Available</th>\n",
       "      <th>Reference Article Retracted</th>\n",
       "      <th>Reference Article Downloaded</th>\n",
       "      <th>Label</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>Top_3_Chunk_IDs</th>\n",
       "      <th>Top_3_Chunk_Texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c001</td>\n",
       "      <td>10.1016/j.est.2021.103553</td>\n",
       "      <td>Heating a residential building using the heat ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Others have aimed to reduce irreversibility or...</td>\n",
       "      <td>r001</td>\n",
       "      <td>10.1155/2021/2087027</td>\n",
       "      <td>A Fault Analysis Method for Three-Phase Induct...</td>\n",
       "      <td>The fault prediction and abductive fault diagn...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiate</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>[00533ca6-92f8-4649-9bba-4d0c2616b39a, 6c75579...</td>\n",
       "      <td>[they cannot effectively diagnose multiple fau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c001</td>\n",
       "      <td>10.1016/j.est.2021.103553</td>\n",
       "      <td>Heating a residential building using the heat ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Some researchers have also studied various hea...</td>\n",
       "      <td>r002</td>\n",
       "      <td>10.1016/j.physa.2018.12.031</td>\n",
       "      <td>Develop 24 dissimilar ANNs by suitable archite...</td>\n",
       "      <td>The artificial neural network optimization met...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiate</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>[a359aaa3-b2cf-47dd-8b5b-414acd5c38ec, 3a469c7...</td>\n",
       "      <td>[properties. The evaluations of nanofluid ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c002</td>\n",
       "      <td>10.1155/2022/4601350</td>\n",
       "      <td>Oxidative Potential and Nanoantioxidant Activi...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>The relative content of total flavonoids in th...</td>\n",
       "      <td>r003</td>\n",
       "      <td>10.1088/1742-6596/1937/1/012038</td>\n",
       "      <td>Lipid Data Acquisition for devices Treatment o...</td>\n",
       "      <td>Recently, the widespread deployment of smart p...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiate</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>[2af26130-5f29-4b0f-b47f-019d9b2d66f1, 8b62706...</td>\n",
       "      <td>[AND RESULT\\nPhotochemical blood performance o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c003</td>\n",
       "      <td>10.1155/2022/2408685</td>\n",
       "      <td>The Choice of Anesthetic Drugs in Outpatient H...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Research has shown that remimazolam tosylate e...</td>\n",
       "      <td>r004</td>\n",
       "      <td>10.1186/s12871-018-0543-3</td>\n",
       "      <td>Effect of propofol on breast cancer cell, the ...</td>\n",
       "      <td>Breast cancer is the second leading cause of c...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiate</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>[4947cbac-d6d7-4f50-9c75-4c101035c923, f9560dc...</td>\n",
       "      <td>[0.001) at 1 year, and 2% (-2 to 6%, non-signi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PubPeer</td>\n",
       "      <td>c004</td>\n",
       "      <td>10.1155/2022/4783847</td>\n",
       "      <td>A Fault-Tolerant Structure for Nano-Power Comm...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>if the efficiency of the routing algorithm is ...</td>\n",
       "      <td>r005</td>\n",
       "      <td>10.36410/jcpr.2022.23.3.312</td>\n",
       "      <td>Analysis and research hotspots of ceramic mate...</td>\n",
       "      <td>From the perspective of scientometrics, comb t...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Unsubstantiate</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>[27f6d293-236a-486b-b3e9-6970081048b0, afd3372...</td>\n",
       "      <td>[space can reflect the intermediary status of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source Citing Article ID         Citing Article DOI  \\\n",
       "0  PubPeer              c001  10.1016/j.est.2021.103553   \n",
       "1  PubPeer              c001  10.1016/j.est.2021.103553   \n",
       "2  PubPeer              c002       10.1155/2022/4601350   \n",
       "3  PubPeer              c003       10.1155/2022/2408685   \n",
       "4  PubPeer              c004       10.1155/2022/4783847   \n",
       "\n",
       "                                Citing Article Title Citing Article Retracted  \\\n",
       "0  Heating a residential building using the heat ...                      Yes   \n",
       "1  Heating a residential building using the heat ...                      Yes   \n",
       "2  Oxidative Potential and Nanoantioxidant Activi...                      Yes   \n",
       "3  The Choice of Anesthetic Drugs in Outpatient H...                      Yes   \n",
       "4  A Fault-Tolerant Structure for Nano-Power Comm...                      Yes   \n",
       "\n",
       "  Citing Article Downloaded       Domain  \\\n",
       "0                       Yes  Engineering   \n",
       "1                       Yes  Engineering   \n",
       "2                       Yes    Chemistry   \n",
       "3                       Yes     Medicine   \n",
       "4                       Yes  Engineering   \n",
       "\n",
       "                             Statement with Citation Reference Article ID  \\\n",
       "0  Others have aimed to reduce irreversibility or...                 r001   \n",
       "1  Some researchers have also studied various hea...                 r002   \n",
       "2  The relative content of total flavonoids in th...                 r003   \n",
       "3  Research has shown that remimazolam tosylate e...                 r004   \n",
       "4  if the efficiency of the routing algorithm is ...                 r005   \n",
       "\n",
       "             Reference Article DOI  \\\n",
       "0             10.1155/2021/2087027   \n",
       "1      10.1016/j.physa.2018.12.031   \n",
       "2  10.1088/1742-6596/1937/1/012038   \n",
       "3        10.1186/s12871-018-0543-3   \n",
       "4      10.36410/jcpr.2022.23.3.312   \n",
       "\n",
       "                             Reference Article Title  \\\n",
       "0  A Fault Analysis Method for Three-Phase Induct...   \n",
       "1  Develop 24 dissimilar ANNs by suitable archite...   \n",
       "2  Lipid Data Acquisition for devices Treatment o...   \n",
       "3  Effect of propofol on breast cancer cell, the ...   \n",
       "4  Analysis and research hotspots of ceramic mate...   \n",
       "\n",
       "                          Reference Article Abstract  \\\n",
       "0  The fault prediction and abductive fault diagn...   \n",
       "1  The artificial neural network optimization met...   \n",
       "2  Recently, the widespread deployment of smart p...   \n",
       "3  Breast cancer is the second leading cause of c...   \n",
       "4  From the perspective of scientometrics, comb t...   \n",
       "\n",
       "  Reference Article PDF Available Reference Article Retracted  \\\n",
       "0                             Yes                          No   \n",
       "1                             Yes                          No   \n",
       "2                             Yes                          No   \n",
       "3                             Yes                          No   \n",
       "4                             Yes                          No   \n",
       "\n",
       "  Reference Article Downloaded           Label Explanation  \\\n",
       "0                          Yes  Unsubstantiate  Irrelevant   \n",
       "1                          Yes  Unsubstantiate  Irrelevant   \n",
       "2                          Yes  Unsubstantiate  Irrelevant   \n",
       "3                          Yes  Unsubstantiate  Irrelevant   \n",
       "4                          Yes  Unsubstantiate  Irrelevant   \n",
       "\n",
       "                                     Top_3_Chunk_IDs  \\\n",
       "0  [00533ca6-92f8-4649-9bba-4d0c2616b39a, 6c75579...   \n",
       "1  [a359aaa3-b2cf-47dd-8b5b-414acd5c38ec, 3a469c7...   \n",
       "2  [2af26130-5f29-4b0f-b47f-019d9b2d66f1, 8b62706...   \n",
       "3  [4947cbac-d6d7-4f50-9c75-4c101035c923, f9560dc...   \n",
       "4  [27f6d293-236a-486b-b3e9-6970081048b0, afd3372...   \n",
       "\n",
       "                                   Top_3_Chunk_Texts  \n",
       "0  [they cannot effectively diagnose multiple fau...  \n",
       "1  [properties. The evaluations of nanofluid ther...  \n",
       "2  [AND RESULT\\nPhotochemical blood performance o...  \n",
       "3  [0.001) at 1 year, and 2% (-2 to 6%, non-signi...  \n",
       "4  [space can reflect the intermediary status of ...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Removing unpickleable private attribute _client\n",
      "WARNING:root:Removing unpickleable private attribute _chunking_tokenizer_fn\n",
      "WARNING:root:Removing unpickleable private attribute _split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _sub_sentence_split_fns\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = f\"../data/dfs/{embedding}{'_no_prev_chunking' if no_prev_chunking else ''}/{grobid_model}/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the DataFrame to a pickle file\n",
    "df2.to_pickle(os.path.join(output_dir, f\"ReferenceErrorDetection_data_with_chunk_info.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
